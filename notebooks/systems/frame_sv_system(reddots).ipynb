{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of honk_sv.manage_audio failed: Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 385, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 324, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 279, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n",
      "/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['mod']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/muncok/DL/projects/sv_system/\")\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "from honk_sv import train as train\n",
    "from honk_sv import model as mod\n",
    "from honk_sv import dataset as dset\n",
    "from honk_sv import system as svs\n",
    "from honk_sv import dataloader as dloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "command: disjoint speaker split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dir = '/home/muncok/DL/dataset/SV_sets/dataframes/'\n",
    "data_dir = '/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/'\n",
    "data_df = pd.read_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Reddots_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import honk_sv.train as hk\n",
    "from honk_sv import model as mod\n",
    "from honk_sv import dataset as dset\n",
    "from honk_sv import system as svs\n",
    "from honk_sv import dataloader as dloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spks = data_df.spk.unique()\n",
    "all_sents = data_df.sent.unique()\n",
    "uttrs_counts = data_df.spk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_spks = list(uttrs_counts[uttrs_counts > 100].index)\n",
    "sv_spks = list(uttrs_counts[uttrs_counts <= 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[random] train:11747, val:2937, test:2937\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "si_df = data_df[data_df.spk.isin(si_spks)]\n",
    "\n",
    "# random sampling\n",
    "si_random_train = si_df.sample(frac=0.8)\n",
    "si_random_test = si_df.drop(index=si_random_train.index)\n",
    "si_random_val = si_random_test\n",
    "print(\"[random] train:{}, val:{}, test:{}\".format(len(si_random_train), len(si_random_val), len(si_random_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../manifests/reddots/si_reddots_train_manifest.csv was written\n",
      "../manifests/reddots/si_reddots_val_manifest.csv was written\n",
      "../manifests/reddots/si_reddots_test_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "tags = ['train', 'val', 'test']\n",
    "# choose a si split\n",
    "sets = {'train':si_random_train, 'val':si_random_val, 'test':si_random_test}\n",
    "manifest_dir = \"../manifests/reddots/\"\n",
    "\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    save_path = os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"reddots\", tag))\n",
    "    with open(save_path, 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = si_spks.index(row.spk)\n",
    "            sample = ','.join([file_path, str(label)])\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)\n",
    "        print(\"{} was written\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../manifests/reddots/sv_reddots_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "# sv write_manifest\n",
    "samples = []\n",
    "save_path = os.path.join(manifest_dir,'sv_{}_manifest.csv'.format(\"reddots\"))\n",
    "sv_df = data_df[data_df.spk.isin(sv_spks)]\n",
    "with open(save_path, 'w') as f:\n",
    "    for index, row in sv_df.iterrows():\n",
    "        file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "        label = sv_spks.index(row.spk)\n",
    "        sample = ','.join([file_path, str(label)])\n",
    "        samples.append(sample)\n",
    "    writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "    writer.writerow(samples)\n",
    "    print(\"{} was written\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SimpleCNN\"\n",
    "dataset = \"reddots\"\n",
    "\n",
    "global_config = dict(model=model, dataset=dataset,\n",
    "                     no_cuda=False,  gpu_no=0,\n",
    "                     n_epochs=100, batch_size=64,\n",
    "                     lr=[0.01], schedule=[np.inf], dev_every=1, seed=0, use_nesterov=False,\n",
    "                     cache_size=32768, momentum=0.9, weight_decay=0.00001,\n",
    "                     num_workers=16, print_step=100,\n",
    "                     splice_length=20\n",
    "                     )\n",
    "\n",
    "builder = train.ConfigBuilder(\n",
    "                dset.SpeechDataset.default_config(),\n",
    "                global_config)\n",
    "parser = builder.build_argparse()\n",
    "si_config = builder.config_from_argparse(parser)\n",
    "si_config['model_class'] = mod.SimpleCNN\n",
    "train.set_seed(si_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_config['input_length'] = int(16000*0.2)\n",
    "si_config['input_format'] = 'fft'\n",
    "manifest_dir = \"../manifests/reddots/\"\n",
    "for tag in ['train', 'val', 'test']:\n",
    "    si_config['{}_manifest'.format(tag)]=os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"reddots\", tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "si_config['n_labels'] = len(si_spks)\n",
    "si_model = si_config['model_class']()\n",
    "time_dim = si_config['input_length']//160+1\n",
    "test_in = Variable(torch.zeros(1,1,time_dim,241), volatile=True)\n",
    "test_out = si_model(test_in)\n",
    "si_model.feat_size = test_out.size(1)\n",
    "si_model.output = nn.Linear(test_out.size(1), si_config[\"n_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #99 accuracy: 0.234375, loss: 3.061197519302368\n",
      "epoch #0, final dev accuracy: 0.21521619946605644\n",
      "saving best model...\n",
      "train step #199 accuracy: 0.1875, loss: 2.975829839706421\n",
      "train step #299 accuracy: 0.3125, loss: 2.740049123764038\n",
      "epoch #1, final dev accuracy: 0.033961432112890926\n",
      "train step #399 accuracy: 0.046875, loss: 3.865417242050171\n",
      "train step #499 accuracy: 0.046875, loss: 3.7768826484680176\n",
      "epoch #2, final dev accuracy: 0.05578995041952708\n",
      "train step #599 accuracy: 0.0, loss: 3.880993366241455\n",
      "train step #699 accuracy: 0.046875, loss: 3.722864866256714\n",
      "epoch #3, final dev accuracy: 0.055831664759725404\n",
      "train step #799 accuracy: 0.09375, loss: 3.684377670288086\n",
      "train step #899 accuracy: 0.078125, loss: 3.6849100589752197\n",
      "epoch #4, final dev accuracy: 0.057148646071701\n",
      "train step #999 accuracy: 0.046875, loss: 3.6804306507110596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9324:\n",
      "Process Process-9323:\n",
      "Process Process-9328:\n",
      "Process Process-9327:\n",
      "Process Process-9313:\n",
      "Process Process-9318:\n",
      "Process Process-9314:\n",
      "Process Process-9316:\n",
      "Process Process-9315:\n",
      "Process Process-9325:\n",
      "Process Process-9317:\n",
      "Process Process-9319:\n",
      "Process Process-9321:\n",
      "Process Process-9320:\n",
      "Process Process-9326:\n",
      "Process Process-9322:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-8a5fc7d75a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msi_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msi_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../models/reddots/si_reddots_0.2s.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msi_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DL/projects/sv_system/honk_sv/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, loaders, model, _collate_fn)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mmodel_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"no_cuda\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mmodel_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mmodel_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f84ff73a278>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 344, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 111, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 111, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 111, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 121, in load\n",
      "    for frame in input_file:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 122, in load\n",
      "    frame = util.buf_to_float(frame, dtype=dtype)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 111, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 122, in load\n",
      "    frame = util.buf_to_float(frame, dtype=dtype)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/audioread/rawread.py\", line 130, in read_data\n",
      "    data = self._file.readframes(block_samples)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 1359, in buf_to_float\n",
      "    return scale * np.frombuffer(x, fmt).astype(dtype)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 312, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 101, in preprocess\n",
      "    bg_noise = np.zeros(in_len)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 121, in load\n",
      "    for frame in input_file:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 1359, in buf_to_float\n",
      "    return scale * np.frombuffer(x, fmt).astype(dtype)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/wave.py\", line 242, in readframes\n",
      "    data = self._data_chunk.read(nframes * self._framesize)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 130, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters, self.input_format)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/audioread/rawread.py\", line 135, in read_data\n",
      "    data = audioop.lin2lin(data, old_width, TARGET_WIDTH)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/chunk.py\", line 136, in read\n",
      "    data = self.file.read(size)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/chunk.py\", line 136, in read\n",
      "    data = self.file.read(size)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 130, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters, self.input_format)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 36, in preprocess_audio\n",
      "    data = fft_audio(data, 0.025, 0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 36, in preprocess_audio\n",
      "    data = fft_audio(data, 0.025, 0.010)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 48, in fft_audio\n",
      "    win_length=win_length, window=windows['hamming'])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 152, in stft\n",
      "    fft_window = util.pad_center(fft_window, n_fft)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 289, in pad_center\n",
      "    return np.pad(data, lengths, **kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1377, in pad\n",
      "    newmat = _append_const(newmat, pad_after, after_val, axis)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 139, in _append_const\n",
      "    axis=axis)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 48, in fft_audio\n",
      "    win_length=win_length, window=windows['hamming'])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 180, in stft\n",
      "    axis=0)[:stft_matrix.shape[0]].conj()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# si_model.load(\"models/reddots/si_reddots_frames_res8.pt\")\n",
    "si_config['n_epochs'] = 100\n",
    "si_config['output_file'] = \"../models/reddots/si_reddots_0.2s.pt\"\n",
    "hk.train(si_config, model=si_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../manifests/reddots/si_reddots_train_manifest.csv'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_config['train_manifest']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'sample', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas\n",
    "import os\n",
    "os.sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Command Dataset\n",
    "Twenty core command words were recorded, with most speakers saying each\n",
    "of them five times. \n",
    "\n",
    "The core words are \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n",
    "\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\",\n",
    "\"Five\", \"Six\", \"Seven\", \"Eight\", and \"Nine\". To help distinguish unrecognized\n",
    "words, \n",
    "\n",
    "there are also ten auxiliary words, which most speakers only said once.\n",
    "These include \"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\",\n",
    "\"Tree\", and \"Wow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "root = \"/home/muncok/DL/dataset/speech_commands/\"\n",
    "wav_files = {}\n",
    "all_spks = []\n",
    "for dirpath, _, filenames in os.walk(root):\n",
    "    if dirpath == root or '_background_noise_' in dirpath: continue\n",
    "    for name in filenames:\n",
    "        sent = dirpath.split('/')[-1]\n",
    "        spk,_,seqID = name.rstrip('.wav').split('_')\n",
    "        uniqID = sent+spk+seqID\n",
    "        all_spks.append(spk)\n",
    "        wav_files[uniqID] = (spk, sent, name)\n",
    "        cnt += 1\n",
    "all_spks = list(set(all_spks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_dict(wav_files, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set df's column names\n",
    "df.columns = ['spk', 'sent', 'file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = [all_spks.index(x) for x in df.spk]\n",
    "df = df.assign(label = new_col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read set devision lists\n",
    "test_list = []\n",
    "with open(\"/home/muncok/DL/dataset/speech_commands/testing_list.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        sent, file = line.rstrip('.wav\\n').split('/')\n",
    "        spk,_,seqID = file.split('_')   \n",
    "        uniqID = sent+spk+seqID\n",
    "        test_list.append(uniqID)\n",
    "\n",
    "val_list = []\n",
    "with open(\"/home/muncok/DL/dataset/speech_commands/validation_list.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        sent, file = line.rstrip('.wav\\n').split('/')\n",
    "        spk,_,seqID = file.split('_')\n",
    "        uniqID = sent+spk+seqID\n",
    "        val_list.append(uniqID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_columns = []\n",
    "for idx in df.index:\n",
    "    if idx in test_list:\n",
    "        set_columns.append('test')\n",
    "    elif idx in val_list:\n",
    "        set_columns.append('val')\n",
    "    else:\n",
    "        set_columns.append('train')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add set column\n",
    "df = df.assign(set = set_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if train, val, and test are disjoint along spk with same sent\n",
    "all_sents = [\n",
    "             \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n",
    "             \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\",\n",
    "             \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n",
    "             \"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\",\n",
    "             \"Tree\",\"Wow\"\n",
    "            ]\n",
    "all_sents = list(map(lambda x: x.lower(), all_sents))\n",
    "\n",
    "for sent in all_sents:\n",
    "    train_sent = df[(df.sent == sent) & (df.set=='train')].spk\n",
    "    val_sent = df[(df.sent == sent) & (df.set=='val')].spk\n",
    "    test_sent = df[(df.sent == sent) & (df.set=='test')].spk\n",
    "    assert not set(train_sent) & set(val_sent) &set(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of speakers: 1881\n",
      "kinds of sents: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"number of speakers: {}\".format(len(all_spks)))\n",
    "print(\"kinds of sents: {}\".format(len(all_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Command_Dataframe.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "command: disjoint speaker split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dir = '/home/muncok/DL/dataset/SV_sets/dataframes/'\n",
    "data_dir = '/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/'\n",
    "data_df = pd.read_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Reddots_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import honk_sv.train as hk\n",
    "import honk_sv.model as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_sents = data_df.sent.value_counts().index[:10]\n",
    "big_sent_df = data_df[data_df.sent.isin(big_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence duration\n",
    "import librosa\n",
    "\n",
    "audio_lengths = []\n",
    "for idx, row in big_sent_df.iterrows():\n",
    "    file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "    x, sr = librosa.load(file_path, sr=16000)\n",
    "    audio_lengths.append(len(x)/16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: correct splits\n",
    "all_spks = data_df.spk.unique()\n",
    "all_sents = data_df.sent.unique()\n",
    "uttrs_counts = data_df.spk.value_counts()\n",
    "sv_spks = list(uttrs_counts.index[-8:])\n",
    "si_spks = list(uttrs_counts.index[:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only big sents\n",
    "data_df = big_sent_df\n",
    "all_spks = data_df.spk.unique()\n",
    "all_sents = data_df.sent.unique()\n",
    "uttrs_counts = data_df.spk.value_counts()\n",
    "sv_spks = sorted(list(uttrs_counts.index[-20:]))\n",
    "si_spks = list(uttrs_counts.index[:-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f0001',\n",
       " 'f0003',\n",
       " 'f0010',\n",
       " 'f0011',\n",
       " 'f0013',\n",
       " 'f0015',\n",
       " 'm0004',\n",
       " 'm0010',\n",
       " 'm0025',\n",
       " 'm0030',\n",
       " 'm0035',\n",
       " 'm0037',\n",
       " 'm0045',\n",
       " 'm0050',\n",
       " 'm0056',\n",
       " 'm0059',\n",
       " 'm0062',\n",
       " 'm0063',\n",
       " 'm0064',\n",
       " 'm0067']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_spks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[random] train:5232, val:654, test:654\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "si_df = data_df[data_df.spk.isin(si_spks)]\n",
    "\n",
    "# random sampling\n",
    "si_random_train = si_df.sample(frac=0.8)\n",
    "si_random_test = si_df.drop(index=si_random_train.index)\n",
    "si_random_val = si_random_test.sample(frac=0.5)\n",
    "si_random_test = si_random_test.drop(index=si_random_val.index) \n",
    "print(\"[random] train:{}, val:{}, test:{}\".format(len(si_random_train), len(si_random_val), len(si_random_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifests/reddots/si_reddots_train_manifest.csv was written\n",
      "manifests/reddots/si_reddots_val_manifest.csv was written\n",
      "manifests/reddots/si_reddots_test_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "tags = ['train', 'val', 'test']\n",
    "# choose a si split\n",
    "sets = {'train':si_random_train, 'val':si_random_val, 'test':si_random_test}\n",
    "manifest_dir = \"manifests/reddots/\"\n",
    "\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    save_path = os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"reddots\", tag))\n",
    "    with open(save_path, 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = si_spks.index(row.spk)\n",
    "            sample = ','.join([file_path, str(label)])\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)\n",
    "        print(\"{} was written\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechResModel (\n",
      "  (conv0): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d (size=[4, 3], stride=[4, 3], padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv4): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv5): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv6): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (output): Linear (45 -> 62)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = \"res8\"\n",
    "dataset = \"reddots\"\n",
    "\n",
    "global_config = dict(model=model, dataset=dataset,\n",
    "                     no_cuda=False,  gpu_no=0,\n",
    "                     n_epochs=30, batch_size=64,\n",
    "                     lr=[0.01], schedule=[np.inf], dev_every=1, seed=0, use_nesterov=False,\n",
    "                     cache_size=32768, momentum=0.9, weight_decay=0.00001,\n",
    "                     num_workers=16, print_step=100,\n",
    "                     splice_length = 20\n",
    "                     )\n",
    "\n",
    "builder = hk.ConfigBuilder(\n",
    "                mod.find_config(model),\n",
    "                mod.SpeechDataset.default_config(dataset),\n",
    "                global_config)\n",
    "parser = builder.build_argparse()\n",
    "si_config = builder.config_from_argparse(parser)\n",
    "si_config['model_class'] = mod.find_model(model)\n",
    "hk.set_seed(si_config)\n",
    "\n",
    "si_config['n_labels'] = 62\n",
    "manifest_dir = \"manifests/reddots/\"\n",
    "for tag in ['train', 'val', 'test']:\n",
    "    si_config['{}_manifest'.format(tag)]=os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"reddots\", tag))\n",
    "\n",
    "si_model = si_config['model_class'](si_config)\n",
    "si_config['input_file'] = \"\"\n",
    "si_config['output_file'] = \"models/reddots/si_reddots_uttrs_res8_moresv.pt\"\n",
    "si_config['input_length'] = int(16000 * 4)\n",
    "print(si_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0, final dev accuracy: 0.1839285714285714\n",
      "saving best model...\n",
      "train step #99 accuracy: 0.203125, loss: 3.2450408935546875\n",
      "epoch #1, final dev accuracy: 0.26584821428571426\n",
      "saving best model...\n",
      "train step #199 accuracy: 0.296875, loss: 2.7089650630950928\n",
      "epoch #2, final dev accuracy: 0.3607142857142857\n",
      "saving best model...\n",
      "train step #299 accuracy: 0.40625, loss: 2.0809857845306396\n",
      "epoch #3, final dev accuracy: 0.42790178571428567\n",
      "saving best model...\n",
      "epoch #4, final dev accuracy: 0.5377232142857143\n",
      "saving best model...\n",
      "train step #399 accuracy: 0.609375, loss: 1.6424047946929932\n",
      "epoch #5, final dev accuracy: 0.5756696428571428\n",
      "saving best model...\n",
      "train step #499 accuracy: 0.671875, loss: 1.670717716217041\n",
      "epoch #6, final dev accuracy: 0.6013392857142856\n",
      "saving best model...\n",
      "train step #599 accuracy: 0.75, loss: 1.34412682056427\n",
      "epoch #7, final dev accuracy: 0.6383928571428571\n",
      "saving best model...\n",
      "epoch #8, final dev accuracy: 0.5705357142857144\n",
      "train step #699 accuracy: 0.796875, loss: 1.0135185718536377\n",
      "epoch #9, final dev accuracy: 0.7270089285714285\n",
      "saving best model...\n",
      "train step #799 accuracy: 0.84375, loss: 0.8812671899795532\n",
      "epoch #10, final dev accuracy: 0.7506696428571429\n",
      "saving best model...\n",
      "train step #899 accuracy: 0.8125, loss: 0.8843327760696411\n",
      "epoch #11, final dev accuracy: 0.8207589285714286\n",
      "saving best model...\n",
      "epoch #12, final dev accuracy: 0.7558035714285715\n",
      "train step #999 accuracy: 0.90625, loss: 0.6650844216346741\n",
      "epoch #13, final dev accuracy: 0.8435267857142857\n",
      "saving best model...\n",
      "train step #1099 accuracy: 0.84375, loss: 0.8122426271438599\n",
      "epoch #14, final dev accuracy: 0.7747767857142857\n",
      "train step #1199 accuracy: 0.875, loss: 0.6329134702682495\n",
      "epoch #15, final dev accuracy: 0.5560267857142857\n",
      "epoch #16, final dev accuracy: 0.8830357142857143\n",
      "saving best model...\n",
      "train step #1299 accuracy: 0.890625, loss: 0.5628459453582764\n",
      "epoch #17, final dev accuracy: 0.8950892857142858\n",
      "saving best model...\n",
      "train step #1399 accuracy: 0.921875, loss: 0.5098864436149597\n",
      "epoch #18, final dev accuracy: 0.896875\n",
      "saving best model...\n",
      "train step #1499 accuracy: 0.96875, loss: 0.45257139205932617\n",
      "epoch #19, final dev accuracy: 0.8995535714285714\n",
      "saving best model...\n",
      "epoch #20, final dev accuracy: 0.9225446428571429\n",
      "saving best model...\n",
      "train step #1599 accuracy: 0.96875, loss: 0.4205358624458313\n",
      "epoch #21, final dev accuracy: 0.9174107142857142\n",
      "train step #1699 accuracy: 0.96875, loss: 0.3806399703025818\n",
      "epoch #22, final dev accuracy: 0.9080357142857143\n",
      "train step #1799 accuracy: 0.90625, loss: 0.4456118047237396\n",
      "epoch #23, final dev accuracy: 0.9064732142857143\n",
      "epoch #24, final dev accuracy: 0.8966517857142857\n",
      "train step #1899 accuracy: 0.96875, loss: 0.3264404535293579\n",
      "epoch #25, final dev accuracy: 0.940625\n",
      "saving best model...\n",
      "train step #1999 accuracy: 0.96875, loss: 0.23096072673797607\n",
      "epoch #26, final dev accuracy: 0.9392857142857143\n",
      "train step #2099 accuracy: 0.96875, loss: 0.23131661117076874\n",
      "epoch #27, final dev accuracy: 0.9370535714285714\n",
      "epoch #28, final dev accuracy: 0.7587053571428571\n",
      "train step #2199 accuracy: 1.0, loss: 0.17194131016731262\n",
      "epoch #29, final dev accuracy: 0.9417410714285713\n",
      "saving best model...\n",
      "final test accuracy: 0.9535655058043118\n"
     ]
    }
   ],
   "source": [
    "hk.train(si_config, model=si_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SV Enrollment & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(sv_spks)\n",
    "enroll_spks = sv_spks[:5]\n",
    "test_spks = sv_spks[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f0003', 'm0056', 'm0030', 'm0059', 'm0045']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enroll_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m0063', 'm0035', 'f0015']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_uttrs = pd.DataFrame()\n",
    "dev_uttrs = pd.DataFrame()\n",
    "enroll_pts = 0.3\n",
    "\n",
    "sv_df = data_df[data_df.spk.isin(sv_spks)]\n",
    "# splits enroll and dev\n",
    "for spk in enroll_spks:\n",
    "    spk_df = sv_df[sv_df.spk == spk]\n",
    "    assert(len(spk_df) != 0)\n",
    "    enls = spk_df.sample(frac=enroll_pts)\n",
    "    devs = spk_df.drop(index=enls.index)\n",
    "    enroll_uttrs = pd.concat([enls, enroll_uttrs])\n",
    "    dev_uttrs = pd.concat([devs, dev_uttrs])\n",
    "    \n",
    "test_uttrs = sv_df[sv_df.spk.isin(test_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_uttrs.to_pickle(\"./dev_uttrs.pkl\")\n",
    "test_uttrs.to_pickle(\"./test_uttrs.pkl\")\n",
    "# dev_uttrs = pd.read_pickle(\"./dev_uttrs.pkl\")\n",
    "# test_uttrs = pd.read_pickle(\"./test_uttrs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./manifests/reddots/enroll/enroll_reddots_f0003_manifest.csv was written\n",
      "./manifests/reddots/enroll/enroll_reddots_m0056_manifest.csv was written\n",
      "./manifests/reddots/enroll/enroll_reddots_m0030_manifest.csv was written\n",
      "./manifests/reddots/enroll/enroll_reddots_m0059_manifest.csv was written\n",
      "./manifests/reddots/enroll/enroll_reddots_m0045_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "manifest_dir = \"./manifests/reddots/enroll/\"\n",
    "# delete existing files\n",
    "for file in os.listdir(manifest_dir):\n",
    "    file_path = os.path.join(manifest_dir, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.unlink(file_path)\n",
    "        \n",
    "\n",
    "for spk in enroll_spks:\n",
    "    samples = []\n",
    "    save_path = os.path.join(manifest_dir,'enroll_{}_{}_manifest.csv'.format(\"reddots\", spk))\n",
    "    with open(save_path, 'w') as f:\n",
    "        for index, row in enroll_uttrs[enroll_uttrs.spk == spk].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = enroll_spks.index(row.spk)\n",
    "            sample = ','.join([file_path, str(label)])\n",
    "            samples.append(sample)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)\n",
    "        print(\"{} was written\".format(save_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_model = si_config['model_class'](si_config)\n",
    "si_model.load(\"models/reddots/si_reddots_uttrs_res8_moresv.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrolling speakers\n",
    "# generating speaker models\n",
    "si_config['batch_size'] = 1\n",
    "manifest_dir = \"./manifests/reddots/enroll/\"\n",
    "spk_models = dict()\n",
    "for spk in enroll_spks:\n",
    "    manifest_path = os.path.join(manifest_dir, 'enroll_{}_{}_manifest.csv'.format(\"reddots\", spk))\n",
    "    si_config['test_manifest'] =  manifest_path\n",
    "    spk_models[spk] = hk.enroll_uttr(si_config, model=si_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0003, m0056: nan\n",
      "f0003, m0030: nan\n",
      "f0003, m0059: nan\n",
      "f0003, m0045: nan\n",
      "m0056, m0030: nan\n",
      "m0056, m0059: nan\n",
      "m0056, m0045: nan\n",
      "m0030, m0059: nan\n",
      "m0030, m0045: nan\n",
      "m0059, m0045: nan\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import itertools\n",
    "\n",
    "for spk1, spk2 in itertools.combinations(enroll_spks,2):\n",
    "    score = 1-cosine(spk_models[spk1], spk_models[spk2])\n",
    "    print(\"{}, {}: {:.2f}\".format(spk1, spk2, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_cosine(spk_model, test_in):\n",
    "    nb_enroll_spks = len(spk_models.keys())\n",
    "    scores = np.zeros(nb_enroll_spks)\n",
    "    for i in range(nb_enroll_spks):\n",
    "        signature = spk_model[i]\n",
    "        scores[i] = 1-cosine(test_in, signature)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SI Acc: 0.9496402877697842\n"
     ]
    }
   ],
   "source": [
    "corrects = 0\n",
    "for idx, row in dev_uttrs.iterrows():\n",
    "    audio_path = os.path.join(data_dir, row.spk, row.file)\n",
    "    emb = hk.embed(si_config, si_model, audio_path)\n",
    "    pred_spk = np.argmax(pairwise_cosine(spk_model, emb))\n",
    "    label = enroll_spks.index(row.spk)\n",
    "    if pred_spk == label:\n",
    "        corrects += 1\n",
    "\n",
    "print(\"SI Acc: {}\".format(corrects/ len(dev_uttrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_total_uttrs = len(dev_uttrs)+len(test_uttrs)\n",
    "n_classes = len(enroll_spks)\n",
    "score_vector = np.zeros((nb_total_uttrs, n_classes))\n",
    "label_vector = np.zeros((nb_total_uttrs, n_classes))\n",
    "\n",
    "spk_model = [v for k,v in spk_models.items()]\n",
    "spk_labels = list(spk_models.keys())\n",
    "\n",
    "i = 0\n",
    "for idx, row in dev_uttrs.iterrows():\n",
    "    audio_path = os.path.join(data_dir, row.spk, row.file)\n",
    "    emb = hk.embed(si_config, si_model, audio_path)\n",
    "    score_vector[i, :] = pairwise_cosine(spk_model, emb)\n",
    "    label = spk_labels.index(row.spk)\n",
    "    label_vector[i, label] = 1\n",
    "    i+=1\n",
    "\n",
    "for idx, row in test_uttrs.iterrows():\n",
    "    audio_path = os.path.join(data_dir, row.spk, row.file)\n",
    "    emb = hk.embed(si_config, si_model, audio_path)\n",
    "    score_vector[i, :] = pairwise_cosine(spk_model, emb)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "eer = dict()\n",
    "thres = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], thres[i] = roc_curve(label_vector[:, i], score_vector[:, i], pos_label=1)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], thres[\"micro\"] = roc_curve(label_vector.ravel(), score_vector.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "eer[\"micro\"] = fpr[\"micro\"][np.nanargmin(np.abs(fpr[\"micro\"] - (1 - tpr[\"micro\"])))]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    eer[i] = fpr[i][np.nanargmin(np.abs(fpr[i] - (1 - tpr[i])))]\n",
    "\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "lw = 2\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "eer[\"macro\"] = fpr[\"macro\"][np.nanargmin(np.abs(fpr[\"macro\"] - (1 - tpr[\"macro\"])))]\n",
    "# Plot all ROC curves\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f}, eer = {1:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"], eer[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f}, eer = {1:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"], eer[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of {0} (area = {1:0.2f}, eer = {2:0.4f})'\n",
    "             ''.format(spk_labels[i], roc_auc[i], eer[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_uttrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112607\n"
     ]
    }
   ],
   "source": [
    "nb_params = 0\n",
    "for param in si_model.parameters():\n",
    "    nb_params += np.prod(param.size())\n",
    "print(nb_params)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

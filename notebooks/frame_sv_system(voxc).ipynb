{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "command: disjoint speaker split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dir = '/home/muncok/DL/dataset/SV_sets/dataframes/'\n",
    "data_dir = '/home/muncok/DL/dataset/SV_sets/voxceleb/'\n",
    "data_df = pd.read_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Voxc_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import honk_sv.train as hk\n",
    "import honk_sv.model as mod\n",
    "import honk_sv.dataset as dset\n",
    "import honk_sv.system as svs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: correct splits\n",
    "all_spks = data_df.spk.unique()\n",
    "uttrs_counts = data_df.spk.value_counts()\n",
    "sv_spks = list(uttrs_counts.index[-40:])\n",
    "si_spks = list(uttrs_counts.index[:-40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[random] train:120605, val:30151, test:30151\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "si_df = data_df[data_df.spk.isin(si_spks)]\n",
    "\n",
    "# random sampling\n",
    "si_random_train = si_df.sample(frac=0.8)\n",
    "si_random_test = si_df.drop(index=si_random_train.index)\n",
    "si_random_val = si_random_test.sample(frac=0.5)\n",
    "si_random_test = si_random_test.drop(index=si_random_val.index) \n",
    "print(\"[random] train:{}, val:{}, test:{}\".format(len(si_random_train), len(si_random_val), len(si_random_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Index' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a7c3925bf49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msi_spks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Index' object is not callable"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "tags = ['train', 'val', 'test']\n",
    "# choose a si split\n",
    "sets = {'train':si_random_train, 'val':si_random_val, 'test':si_random_test}\n",
    "manifest_dir = \"../manifests/voxc/\"\n",
    "\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    save_path = os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"voxc\", tag))\n",
    "    with open(save_path, 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = si_spks.index(row.spk)\n",
    "            sample = ','.join([file_path, str(label)])\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)\n",
    "        print(\"{} was written\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechResModel (\n",
      "  (conv0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d (size=[4, 3], stride=[4, 3], padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (output): Linear (128 -> 1211)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = \"res8-wide\"\n",
    "dataset = \"voxc\"\n",
    "\n",
    "global_config = dict(model=model, dataset=dataset,\n",
    "                     no_cuda=False,  gpu_no=0,\n",
    "                     n_epochs=100, batch_size=128,\n",
    "                     lr=[0.001], schedule=[np.inf], dev_every=1, seed=0, use_nesterov=False,\n",
    "                     cache_size=32768, momentum=0.9, weight_decay=0.00001,\n",
    "                     num_workers=32, print_step=100,\n",
    "                     splice_length = 40\n",
    "                     )\n",
    "\n",
    "builder = hk.ConfigBuilder(\n",
    "                mod.find_config(model),\n",
    "                dset.SpeechDataset.default_config(dataset),\n",
    "                global_config)\n",
    "parser = builder.build_argparse()\n",
    "si_config = builder.config_from_argparse(parser)\n",
    "si_config['model_class'] = mod.find_model(model)\n",
    "hk.set_seed(si_config)\n",
    "\n",
    "si_config['n_labels'] = len(si_spks)\n",
    "manifest_dir = \"manifests/voxc/\"\n",
    "for tag in ['train', 'val', 'test']:\n",
    "    si_config['{}_manifest'.format(tag)]=os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"voxc\", tag))\n",
    "\n",
    "si_model = si_config['model_class'](si_config)\n",
    "si_config['output_file'] = \"models/voxc/si_voxc_frames_res8w_1.pt\"\n",
    "print(si_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f4b46285898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 241, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 237, in _shutdown_workers\n",
      "    self.index_queue.put(None)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #99 accuracy: 0.2421875, loss: 4.177387237548828\n",
      "train step #199 accuracy: 0.2421875, loss: 4.276266574859619\n",
      "train step #299 accuracy: 0.265625, loss: 3.9817466735839844\n",
      "train step #399 accuracy: 0.2578125, loss: 3.9527950286865234\n",
      "train step #499 accuracy: 0.203125, loss: 4.414542198181152\n",
      "train step #599 accuracy: 0.21875, loss: 4.176668167114258\n",
      "train step #699 accuracy: 0.2734375, loss: 3.986218214035034\n",
      "train step #799 accuracy: 0.28125, loss: 3.986651659011841\n",
      "train step #899 accuracy: 0.25, loss: 4.237125873565674\n",
      "epoch #0, final dev accuracy: 0.24478019067796608\n",
      "saving best model...\n",
      "train step #999 accuracy: 0.265625, loss: 3.9438414573669434\n",
      "train step #1099 accuracy: 0.265625, loss: 3.9199578762054443\n",
      "train step #1199 accuracy: 0.2109375, loss: 4.135591983795166\n",
      "train step #1299 accuracy: 0.25, loss: 3.949500322341919\n",
      "train step #1399 accuracy: 0.2890625, loss: 3.8404879570007324\n",
      "train step #1499 accuracy: 0.2578125, loss: 4.059499740600586\n",
      "train step #1599 accuracy: 0.2265625, loss: 4.438430309295654\n",
      "train step #1699 accuracy: 0.28125, loss: 3.8978397846221924\n",
      "train step #1799 accuracy: 0.2421875, loss: 4.149833679199219\n",
      "epoch #1, final dev accuracy: 0.23751588983050848\n",
      "train step #1899 accuracy: 0.2890625, loss: 3.91210675239563\n",
      "train step #1999 accuracy: 0.265625, loss: 3.8784282207489014\n",
      "train step #2099 accuracy: 0.21875, loss: 4.1222333908081055\n",
      "train step #2199 accuracy: 0.234375, loss: 4.493922710418701\n",
      "train step #2299 accuracy: 0.2109375, loss: 4.194676876068115\n",
      "train step #2399 accuracy: 0.2421875, loss: 4.198912620544434\n",
      "train step #2499 accuracy: 0.25, loss: 4.058197021484375\n",
      "train step #2599 accuracy: 0.2265625, loss: 4.169767379760742\n",
      "train step #2699 accuracy: 0.328125, loss: 3.7753474712371826\n",
      "train step #2799 accuracy: 0.2578125, loss: 4.063884258270264\n",
      "epoch #2, final dev accuracy: 0.24850635593220338\n",
      "saving best model...\n",
      "train step #2899 accuracy: 0.2421875, loss: 3.9820644855499268\n",
      "train step #2999 accuracy: 0.2734375, loss: 3.861758232116699\n",
      "train step #3099 accuracy: 0.265625, loss: 4.002406120300293\n",
      "train step #3199 accuracy: 0.3125, loss: 3.7939159870147705\n",
      "train step #3299 accuracy: 0.25, loss: 4.027764320373535\n",
      "train step #3399 accuracy: 0.21875, loss: 4.228823661804199\n",
      "train step #3499 accuracy: 0.21875, loss: 4.147693157196045\n",
      "train step #3599 accuracy: 0.203125, loss: 4.237961292266846\n",
      "train step #3699 accuracy: 0.265625, loss: 4.10418176651001\n",
      "epoch #3, final dev accuracy: 0.2478893008474576\n",
      "train step #3799 accuracy: 0.2421875, loss: 3.9588072299957275\n",
      "train step #3899 accuracy: 0.3046875, loss: 3.875089168548584\n",
      "train step #3999 accuracy: 0.234375, loss: 4.269059181213379\n",
      "train step #4099 accuracy: 0.265625, loss: 4.010598182678223\n",
      "train step #4199 accuracy: 0.21875, loss: 3.9632132053375244\n",
      "train step #4299 accuracy: 0.203125, loss: 4.265303134918213\n",
      "train step #4399 accuracy: 0.203125, loss: 4.1533989906311035\n",
      "train step #4499 accuracy: 0.2265625, loss: 4.290093421936035\n",
      "train step #4599 accuracy: 0.25, loss: 3.8721280097961426\n",
      "train step #4699 accuracy: 0.296875, loss: 3.904677391052246\n",
      "epoch #4, final dev accuracy: 0.24709745762711863\n",
      "train step #4799 accuracy: 0.296875, loss: 3.9377434253692627\n",
      "train step #4899 accuracy: 0.2578125, loss: 3.9013593196868896\n",
      "train step #4999 accuracy: 0.2265625, loss: 3.8684334754943848\n",
      "train step #5099 accuracy: 0.28125, loss: 4.0727338790893555\n",
      "train step #5199 accuracy: 0.234375, loss: 4.263997554779053\n",
      "train step #5299 accuracy: 0.3125, loss: 3.844353199005127\n",
      "train step #5399 accuracy: 0.265625, loss: 3.8933985233306885\n",
      "train step #5499 accuracy: 0.25, loss: 4.065996170043945\n",
      "train step #5599 accuracy: 0.2109375, loss: 4.135400772094727\n",
      "epoch #5, final dev accuracy: 0.2500450211864407\n",
      "saving best model...\n",
      "train step #5699 accuracy: 0.2890625, loss: 3.8445310592651367\n",
      "train step #5799 accuracy: 0.203125, loss: 4.060511112213135\n",
      "train step #5899 accuracy: 0.2421875, loss: 4.153713703155518\n",
      "train step #5999 accuracy: 0.25, loss: 4.255556106567383\n",
      "train step #6099 accuracy: 0.28125, loss: 4.09605073928833\n",
      "train step #6199 accuracy: 0.3046875, loss: 3.771304130554199\n",
      "train step #6299 accuracy: 0.171875, loss: 4.258360385894775\n",
      "train step #6399 accuracy: 0.2421875, loss: 4.102545738220215\n",
      "train step #6499 accuracy: 0.21875, loss: 3.9717419147491455\n",
      "epoch #6, final dev accuracy: 0.251541313559322\n",
      "saving best model...\n",
      "train step #6599 accuracy: 0.234375, loss: 3.9876761436462402\n",
      "train step #6699 accuracy: 0.1640625, loss: 4.283591270446777\n",
      "train step #6799 accuracy: 0.2421875, loss: 4.086171627044678\n",
      "train step #6899 accuracy: 0.21875, loss: 4.122999668121338\n",
      "train step #6999 accuracy: 0.203125, loss: 4.125715255737305\n",
      "train step #7099 accuracy: 0.3203125, loss: 3.75394344329834\n",
      "train step #7199 accuracy: 0.21875, loss: 4.2792792320251465\n",
      "train step #7299 accuracy: 0.234375, loss: 3.898432970046997\n",
      "train step #7399 accuracy: 0.265625, loss: 3.974533796310425\n",
      "train step #7499 accuracy: 0.1796875, loss: 4.393474578857422\n",
      "epoch #7, final dev accuracy: 0.2534242584745763\n",
      "saving best model...\n",
      "train step #7599 accuracy: 0.2109375, loss: 4.096622943878174\n",
      "train step #7699 accuracy: 0.2578125, loss: 4.149681091308594\n",
      "train step #7799 accuracy: 0.359375, loss: 3.622690439224243\n",
      "train step #7899 accuracy: 0.2578125, loss: 3.9753904342651367\n",
      "train step #7999 accuracy: 0.3359375, loss: 3.8490853309631348\n",
      "train step #8099 accuracy: 0.21875, loss: 3.9714834690093994\n",
      "train step #8199 accuracy: 0.265625, loss: 4.006843090057373\n",
      "train step #8299 accuracy: 0.25, loss: 3.927079916000366\n",
      "train step #8399 accuracy: 0.1875, loss: 4.444983005523682\n",
      "epoch #8, final dev accuracy: 0.2526006355932204\n",
      "train step #8499 accuracy: 0.2890625, loss: 3.8319592475891113\n",
      "train step #8599 accuracy: 0.203125, loss: 4.417121887207031\n",
      "train step #8699 accuracy: 0.234375, loss: 4.164951324462891\n",
      "train step #8799 accuracy: 0.2578125, loss: 4.177832126617432\n",
      "train step #8899 accuracy: 0.28125, loss: 3.8844821453094482\n",
      "train step #8999 accuracy: 0.234375, loss: 3.9816009998321533\n",
      "train step #9099 accuracy: 0.3046875, loss: 3.664513111114502\n",
      "train step #9199 accuracy: 0.203125, loss: 4.016829490661621\n",
      "train step #9299 accuracy: 0.25, loss: 4.079519271850586\n",
      "train step #9399 accuracy: 0.2265625, loss: 4.0854172706604\n",
      "epoch #9, final dev accuracy: 0.253114406779661\n",
      "train step #9499 accuracy: 0.3125, loss: 4.007078170776367\n",
      "train step #9599 accuracy: 0.25, loss: 4.004641056060791\n",
      "train step #9699 accuracy: 0.28125, loss: 3.9689412117004395\n",
      "train step #9799 accuracy: 0.2734375, loss: 4.080782413482666\n",
      "train step #9899 accuracy: 0.265625, loss: 4.1350250244140625\n",
      "train step #9999 accuracy: 0.28125, loss: 3.9789860248565674\n",
      "train step #10099 accuracy: 0.3125, loss: 3.7166614532470703\n",
      "train step #10199 accuracy: 0.28125, loss: 4.023143768310547\n",
      "train step #10299 accuracy: 0.2578125, loss: 3.890385866165161\n",
      "epoch #10, final dev accuracy: 0.25698093220338986\n",
      "saving best model...\n",
      "train step #10399 accuracy: 0.234375, loss: 4.093366622924805\n",
      "train step #10499 accuracy: 0.265625, loss: 3.8766543865203857\n",
      "train step #10599 accuracy: 0.3203125, loss: 3.7227277755737305\n",
      "train step #10699 accuracy: 0.2734375, loss: 3.904278039932251\n",
      "train step #10799 accuracy: 0.234375, loss: 4.207424640655518\n",
      "train step #10899 accuracy: 0.265625, loss: 3.978121519088745\n",
      "train step #10999 accuracy: 0.265625, loss: 3.8745510578155518\n",
      "train step #11099 accuracy: 0.21875, loss: 3.980454921722412\n",
      "train step #11199 accuracy: 0.3046875, loss: 3.580951690673828\n",
      "train step #11299 accuracy: 0.21875, loss: 4.059388160705566\n",
      "epoch #11, final dev accuracy: 0.25649629237288135\n",
      "train step #11399 accuracy: 0.3203125, loss: 3.685870885848999\n",
      "train step #11499 accuracy: 0.265625, loss: 3.9718658924102783\n",
      "train step #11599 accuracy: 0.28125, loss: 3.9335005283355713\n",
      "train step #11699 accuracy: 0.296875, loss: 3.849134922027588\n",
      "train step #11799 accuracy: 0.2578125, loss: 4.215035438537598\n",
      "train step #11899 accuracy: 0.2265625, loss: 4.222444534301758\n",
      "train step #11999 accuracy: 0.2421875, loss: 4.015774726867676\n",
      "train step #12099 accuracy: 0.2890625, loss: 3.7101643085479736\n",
      "train step #12199 accuracy: 0.265625, loss: 3.8535187244415283\n",
      "epoch #12, final dev accuracy: 0.258125\n",
      "saving best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #12299 accuracy: 0.28125, loss: 4.026044845581055\n",
      "train step #12399 accuracy: 0.3046875, loss: 3.7904458045959473\n",
      "train step #12499 accuracy: 0.234375, loss: 3.9121408462524414\n",
      "train step #12599 accuracy: 0.2734375, loss: 3.941270351409912\n",
      "train step #12699 accuracy: 0.25, loss: 3.924314260482788\n",
      "train step #12799 accuracy: 0.296875, loss: 3.902076244354248\n",
      "train step #12899 accuracy: 0.1875, loss: 4.136517524719238\n",
      "train step #12999 accuracy: 0.28125, loss: 3.8530654907226562\n",
      "train step #13099 accuracy: 0.28125, loss: 3.721367597579956\n",
      "epoch #13, final dev accuracy: 0.2567717161016949\n",
      "train step #13199 accuracy: 0.265625, loss: 4.134958744049072\n",
      "train step #13299 accuracy: 0.2890625, loss: 3.741032600402832\n",
      "train step #13399 accuracy: 0.203125, loss: 4.2119669914245605\n",
      "train step #13499 accuracy: 0.265625, loss: 3.97184157371521\n",
      "train step #13599 accuracy: 0.28125, loss: 4.124701976776123\n",
      "train step #13699 accuracy: 0.265625, loss: 3.7815630435943604\n",
      "train step #13799 accuracy: 0.28125, loss: 3.9334540367126465\n",
      "train step #13899 accuracy: 0.28125, loss: 3.8993618488311768\n",
      "train step #13999 accuracy: 0.2265625, loss: 4.338501930236816\n",
      "train step #14099 accuracy: 0.265625, loss: 3.839306354522705\n",
      "epoch #14, final dev accuracy: 0.2572934322033898\n",
      "train step #14199 accuracy: 0.296875, loss: 3.959944725036621\n",
      "train step #14299 accuracy: 0.2421875, loss: 4.171868801116943\n",
      "train step #14399 accuracy: 0.28125, loss: 3.8802616596221924\n",
      "train step #14499 accuracy: 0.25, loss: 3.8830015659332275\n",
      "train step #14599 accuracy: 0.21875, loss: 4.138158798217773\n",
      "train step #14699 accuracy: 0.203125, loss: 4.138371467590332\n",
      "train step #14799 accuracy: 0.28125, loss: 3.9884541034698486\n",
      "train step #14899 accuracy: 0.2890625, loss: 3.8077874183654785\n",
      "train step #14999 accuracy: 0.2734375, loss: 3.799631357192993\n",
      "epoch #15, final dev accuracy: 0.25345074152542374\n",
      "train step #15099 accuracy: 0.3046875, loss: 3.8406503200531006\n",
      "train step #15199 accuracy: 0.3046875, loss: 3.748474597930908\n",
      "train step #15299 accuracy: 0.3203125, loss: 3.862455129623413\n",
      "train step #15399 accuracy: 0.2578125, loss: 3.9913744926452637\n",
      "train step #15499 accuracy: 0.2890625, loss: 3.907036304473877\n",
      "train step #15599 accuracy: 0.2109375, loss: 4.145609378814697\n",
      "train step #15699 accuracy: 0.2578125, loss: 4.0890583992004395\n",
      "train step #15799 accuracy: 0.234375, loss: 3.901228666305542\n",
      "train step #15899 accuracy: 0.25, loss: 4.099171161651611\n",
      "train step #15999 accuracy: 0.2265625, loss: 4.098891735076904\n",
      "epoch #16, final dev accuracy: 0.25588453389830507\n",
      "train step #16099 accuracy: 0.3125, loss: 3.710949182510376\n",
      "train step #16199 accuracy: 0.234375, loss: 4.17840051651001\n",
      "train step #16299 accuracy: 0.2890625, loss: 3.630690574645996\n",
      "train step #16399 accuracy: 0.234375, loss: 4.1758527755737305\n",
      "train step #16499 accuracy: 0.1953125, loss: 4.292039394378662\n",
      "train step #16599 accuracy: 0.2578125, loss: 4.108593940734863\n",
      "train step #16699 accuracy: 0.2578125, loss: 3.957606077194214\n",
      "train step #16799 accuracy: 0.2421875, loss: 4.046226501464844\n",
      "train step #16899 accuracy: 0.25, loss: 3.982588768005371\n",
      "epoch #17, final dev accuracy: 0.2616710805084746\n",
      "saving best model...\n",
      "train step #16999 accuracy: 0.296875, loss: 3.7724571228027344\n",
      "train step #17099 accuracy: 0.1953125, loss: 4.137093544006348\n",
      "train step #17199 accuracy: 0.2421875, loss: 4.0327534675598145\n",
      "train step #17299 accuracy: 0.2734375, loss: 3.875406265258789\n",
      "train step #17399 accuracy: 0.3046875, loss: 4.020448684692383\n",
      "train step #17499 accuracy: 0.203125, loss: 4.11492919921875\n",
      "train step #17599 accuracy: 0.265625, loss: 4.107016086578369\n",
      "train step #17699 accuracy: 0.3671875, loss: 3.58085036277771\n",
      "train step #17799 accuracy: 0.2421875, loss: 4.135621547698975\n",
      "epoch #18, final dev accuracy: 0.2660884533898305\n",
      "saving best model...\n",
      "train step #17899 accuracy: 0.2421875, loss: 4.090804100036621\n",
      "train step #17999 accuracy: 0.2578125, loss: 3.7584569454193115\n",
      "train step #18099 accuracy: 0.296875, loss: 3.806809902191162\n",
      "train step #18199 accuracy: 0.296875, loss: 3.8772220611572266\n",
      "train step #18299 accuracy: 0.2890625, loss: 3.9134175777435303\n",
      "train step #18399 accuracy: 0.2578125, loss: 4.127473831176758\n",
      "train step #18499 accuracy: 0.28125, loss: 3.9319815635681152\n",
      "train step #18599 accuracy: 0.2265625, loss: 3.8745930194854736\n",
      "train step #18699 accuracy: 0.2890625, loss: 3.910647392272949\n",
      "train step #18799 accuracy: 0.28125, loss: 4.0219926834106445\n",
      "epoch #19, final dev accuracy: 0.26038400423728814\n",
      "train step #18899 accuracy: 0.3046875, loss: 3.9144203662872314\n",
      "train step #18999 accuracy: 0.296875, loss: 3.701160430908203\n",
      "train step #19099 accuracy: 0.25, loss: 3.896296262741089\n",
      "train step #19199 accuracy: 0.2890625, loss: 3.9720005989074707\n",
      "train step #19299 accuracy: 0.296875, loss: 3.887889862060547\n",
      "train step #19399 accuracy: 0.265625, loss: 3.877890110015869\n",
      "train step #19499 accuracy: 0.28125, loss: 3.9902288913726807\n",
      "train step #19599 accuracy: 0.2734375, loss: 4.133027076721191\n",
      "train step #19699 accuracy: 0.296875, loss: 3.8369665145874023\n",
      "epoch #20, final dev accuracy: 0.2580111228813559\n",
      "train step #19799 accuracy: 0.234375, loss: 4.279767036437988\n",
      "train step #19899 accuracy: 0.2734375, loss: 3.8900179862976074\n",
      "train step #19999 accuracy: 0.25, loss: 3.9755542278289795\n",
      "train step #20099 accuracy: 0.34375, loss: 3.6507606506347656\n",
      "train step #20199 accuracy: 0.25, loss: 3.9138760566711426\n",
      "train step #20299 accuracy: 0.3125, loss: 3.794438123703003\n",
      "train step #20399 accuracy: 0.25, loss: 3.9499545097351074\n",
      "train step #20499 accuracy: 0.265625, loss: 3.873167037963867\n",
      "train step #20599 accuracy: 0.234375, loss: 4.193032264709473\n",
      "train step #20699 accuracy: 0.2890625, loss: 3.9129257202148438\n",
      "epoch #21, final dev accuracy: 0.2626588983050847\n",
      "train step #20799 accuracy: 0.3359375, loss: 3.6220498085021973\n",
      "train step #20899 accuracy: 0.3203125, loss: 3.813971519470215\n",
      "train step #20999 accuracy: 0.3828125, loss: 3.4182567596435547\n",
      "train step #21099 accuracy: 0.2421875, loss: 3.8464300632476807\n",
      "train step #21199 accuracy: 0.3671875, loss: 3.6409802436828613\n",
      "train step #21299 accuracy: 0.296875, loss: 4.03067684173584\n",
      "train step #21399 accuracy: 0.2421875, loss: 4.1916399002075195\n",
      "train step #21499 accuracy: 0.234375, loss: 4.1252121925354\n",
      "train step #21599 accuracy: 0.2890625, loss: 3.871586799621582\n",
      "epoch #22, final dev accuracy: 0.2597139830508474\n",
      "train step #21699 accuracy: 0.2265625, loss: 4.124563217163086\n",
      "train step #21799 accuracy: 0.359375, loss: 3.5166609287261963\n",
      "train step #21899 accuracy: 0.28125, loss: 3.8336808681488037\n",
      "train step #21999 accuracy: 0.21875, loss: 4.0879926681518555\n",
      "train step #22099 accuracy: 0.2421875, loss: 4.173088550567627\n",
      "train step #22199 accuracy: 0.265625, loss: 3.811650037765503\n",
      "train step #22299 accuracy: 0.2265625, loss: 3.8329856395721436\n",
      "train step #22399 accuracy: 0.3046875, loss: 3.7946414947509766\n",
      "train step #22499 accuracy: 0.296875, loss: 3.786257743835449\n",
      "train step #22599 accuracy: 0.25, loss: 3.7759785652160645\n",
      "epoch #23, final dev accuracy: 0.2622272245762712\n",
      "train step #22699 accuracy: 0.359375, loss: 3.5675530433654785\n",
      "train step #22799 accuracy: 0.2734375, loss: 3.8456127643585205\n",
      "train step #22899 accuracy: 0.2734375, loss: 3.9042515754699707\n",
      "train step #22999 accuracy: 0.25, loss: 3.8902347087860107\n",
      "train step #23099 accuracy: 0.34375, loss: 3.892456293106079\n",
      "train step #23199 accuracy: 0.265625, loss: 4.14244270324707\n",
      "train step #23299 accuracy: 0.296875, loss: 3.8616082668304443\n",
      "train step #23399 accuracy: 0.328125, loss: 3.806164503097534\n",
      "train step #23499 accuracy: 0.3125, loss: 3.8128490447998047\n",
      "epoch #24, final dev accuracy: 0.26162605932203387\n",
      "train step #23599 accuracy: 0.2109375, loss: 4.081971645355225\n",
      "train step #23699 accuracy: 0.3203125, loss: 3.9080963134765625\n",
      "train step #23799 accuracy: 0.1953125, loss: 4.123601913452148\n",
      "train step #23899 accuracy: 0.2421875, loss: 4.104291915893555\n",
      "train step #23999 accuracy: 0.171875, loss: 4.21806001663208\n",
      "train step #24099 accuracy: 0.3359375, loss: 3.6373181343078613\n",
      "train step #24199 accuracy: 0.3125, loss: 3.8510196208953857\n",
      "train step #24299 accuracy: 0.234375, loss: 4.117866039276123\n",
      "train step #24399 accuracy: 0.2890625, loss: 3.800036668777466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #25, final dev accuracy: 0.2664936440677966\n",
      "saving best model...\n",
      "train step #24499 accuracy: 0.328125, loss: 3.752011299133301\n",
      "train step #24599 accuracy: 0.296875, loss: 3.706578254699707\n",
      "train step #24699 accuracy: 0.28125, loss: 3.8855602741241455\n",
      "train step #24799 accuracy: 0.2734375, loss: 4.014851093292236\n",
      "train step #24899 accuracy: 0.265625, loss: 3.997891426086426\n",
      "train step #24999 accuracy: 0.265625, loss: 3.851119041442871\n",
      "train step #25099 accuracy: 0.2265625, loss: 3.879394054412842\n",
      "train step #25199 accuracy: 0.3515625, loss: 3.7623820304870605\n",
      "train step #25299 accuracy: 0.2421875, loss: 3.787954807281494\n",
      "train step #25399 accuracy: 0.234375, loss: 3.9907121658325195\n",
      "epoch #26, final dev accuracy: 0.26353283898305085\n",
      "train step #25499 accuracy: 0.28125, loss: 3.8612492084503174\n",
      "train step #25599 accuracy: 0.203125, loss: 4.114034175872803\n",
      "train step #25699 accuracy: 0.2890625, loss: 3.8466856479644775\n",
      "train step #25799 accuracy: 0.2578125, loss: 4.052722930908203\n",
      "train step #25899 accuracy: 0.328125, loss: 3.804661989212036\n",
      "train step #25999 accuracy: 0.2421875, loss: 4.082622528076172\n",
      "train step #26099 accuracy: 0.265625, loss: 4.003491401672363\n",
      "train step #26199 accuracy: 0.28125, loss: 3.979618787765503\n",
      "train step #26299 accuracy: 0.3046875, loss: 3.7343642711639404\n",
      "epoch #27, final dev accuracy: 0.26890625\n",
      "saving best model...\n",
      "train step #26399 accuracy: 0.2890625, loss: 3.9827778339385986\n",
      "train step #26499 accuracy: 0.2890625, loss: 3.6863341331481934\n",
      "train step #26599 accuracy: 0.1796875, loss: 4.1475019454956055\n",
      "train step #26699 accuracy: 0.3203125, loss: 3.8144309520721436\n",
      "train step #26799 accuracy: 0.3046875, loss: 3.78586745262146\n",
      "train step #26899 accuracy: 0.3359375, loss: 3.711313486099243\n",
      "train step #26999 accuracy: 0.2890625, loss: 3.761399507522583\n",
      "train step #27099 accuracy: 0.28125, loss: 4.068538188934326\n",
      "train step #27199 accuracy: 0.28125, loss: 3.845496416091919\n",
      "train step #27299 accuracy: 0.2265625, loss: 3.9625933170318604\n",
      "epoch #28, final dev accuracy: 0.2577462923728814\n",
      "train step #27399 accuracy: 0.25, loss: 3.925079584121704\n",
      "train step #27499 accuracy: 0.265625, loss: 3.833761692047119\n",
      "train step #27599 accuracy: 0.328125, loss: 3.62601375579834\n",
      "train step #27699 accuracy: 0.2578125, loss: 3.683957099914551\n",
      "train step #27799 accuracy: 0.3125, loss: 3.6343581676483154\n",
      "train step #27899 accuracy: 0.328125, loss: 3.911787986755371\n",
      "train step #27999 accuracy: 0.21875, loss: 4.120080947875977\n",
      "train step #28099 accuracy: 0.28125, loss: 3.906395673751831\n",
      "train step #28199 accuracy: 0.4140625, loss: 3.473792791366577\n",
      "epoch #29, final dev accuracy: 0.2635434322033898\n",
      "train step #28299 accuracy: 0.296875, loss: 3.896699905395508\n",
      "train step #28399 accuracy: 0.265625, loss: 3.8651320934295654\n",
      "train step #28499 accuracy: 0.2890625, loss: 3.6644954681396484\n",
      "train step #28599 accuracy: 0.21875, loss: 3.9393880367279053\n",
      "train step #28699 accuracy: 0.296875, loss: 3.665966510772705\n",
      "train step #28799 accuracy: 0.3671875, loss: 3.4477102756500244\n",
      "train step #28899 accuracy: 0.3125, loss: 3.7175064086914062\n",
      "train step #28999 accuracy: 0.203125, loss: 3.853044271469116\n",
      "train step #29099 accuracy: 0.1953125, loss: 4.0934953689575195\n",
      "train step #29199 accuracy: 0.2734375, loss: 3.764359712600708\n",
      "epoch #30, final dev accuracy: 0.2680561440677966\n",
      "train step #29299 accuracy: 0.3125, loss: 3.7471961975097656\n",
      "train step #29399 accuracy: 0.3515625, loss: 3.58056640625\n",
      "train step #29499 accuracy: 0.3046875, loss: 3.7584328651428223\n",
      "train step #29599 accuracy: 0.2890625, loss: 3.8298747539520264\n",
      "train step #29699 accuracy: 0.296875, loss: 3.8441355228424072\n",
      "train step #29799 accuracy: 0.2421875, loss: 3.881566047668457\n",
      "train step #29899 accuracy: 0.203125, loss: 4.162056922912598\n",
      "train step #29999 accuracy: 0.265625, loss: 3.8094589710235596\n",
      "train step #30099 accuracy: 0.3125, loss: 3.8475852012634277\n",
      "epoch #31, final dev accuracy: 0.26521716101694914\n",
      "train step #30199 accuracy: 0.28125, loss: 3.969449281692505\n",
      "train step #30299 accuracy: 0.40625, loss: 3.45682692527771\n",
      "train step #30399 accuracy: 0.296875, loss: 3.757998466491699\n",
      "train step #30499 accuracy: 0.25, loss: 3.884305477142334\n",
      "train step #30599 accuracy: 0.3203125, loss: 3.753215789794922\n",
      "train step #30699 accuracy: 0.25, loss: 3.8446695804595947\n",
      "train step #30799 accuracy: 0.265625, loss: 3.9750657081604004\n",
      "train step #30899 accuracy: 0.2578125, loss: 3.909954786300659\n",
      "train step #30999 accuracy: 0.25, loss: 4.032084941864014\n",
      "epoch #32, final dev accuracy: 0.26699417372881357\n",
      "train step #31099 accuracy: 0.25, loss: 3.729259490966797\n",
      "train step #31199 accuracy: 0.203125, loss: 4.016693592071533\n",
      "train step #31299 accuracy: 0.25, loss: 3.898965835571289\n",
      "train step #31399 accuracy: 0.3203125, loss: 3.8117175102233887\n",
      "train step #31499 accuracy: 0.2734375, loss: 3.9448463916778564\n",
      "train step #31599 accuracy: 0.2421875, loss: 3.980052947998047\n",
      "train step #31699 accuracy: 0.3046875, loss: 3.9100852012634277\n",
      "train step #31799 accuracy: 0.28125, loss: 3.839712381362915\n",
      "train step #31899 accuracy: 0.296875, loss: 3.8811419010162354\n",
      "train step #31999 accuracy: 0.234375, loss: 4.159820079803467\n",
      "epoch #33, final dev accuracy: 0.26594809322033897\n",
      "train step #32099 accuracy: 0.2734375, loss: 3.8696374893188477\n",
      "train step #32199 accuracy: 0.3046875, loss: 3.575103759765625\n",
      "train step #32299 accuracy: 0.3515625, loss: 3.5977065563201904\n",
      "train step #32399 accuracy: 0.2734375, loss: 4.029695987701416\n",
      "train step #32499 accuracy: 0.296875, loss: 3.6819963455200195\n",
      "train step #32599 accuracy: 0.296875, loss: 3.746283769607544\n",
      "train step #32699 accuracy: 0.2265625, loss: 4.085015296936035\n",
      "train step #32799 accuracy: 0.2890625, loss: 3.955288887023926\n",
      "train step #32899 accuracy: 0.234375, loss: 3.788681983947754\n",
      "epoch #34, final dev accuracy: 0.2688003177966102\n",
      "train step #32999 accuracy: 0.296875, loss: 3.7929766178131104\n",
      "train step #33099 accuracy: 0.265625, loss: 3.7973806858062744\n",
      "train step #33199 accuracy: 0.3046875, loss: 3.944819927215576\n",
      "train step #33299 accuracy: 0.34375, loss: 3.572166919708252\n",
      "train step #33399 accuracy: 0.3125, loss: 3.9247663021087646\n",
      "train step #33499 accuracy: 0.359375, loss: 3.5357043743133545\n",
      "train step #33599 accuracy: 0.2734375, loss: 3.504648447036743\n",
      "train step #33699 accuracy: 0.328125, loss: 3.4472103118896484\n",
      "train step #33799 accuracy: 0.265625, loss: 3.9434709548950195\n",
      "train step #33899 accuracy: 0.203125, loss: 3.993917942047119\n",
      "epoch #35, final dev accuracy: 0.2725370762711864\n",
      "saving best model...\n",
      "train step #33999 accuracy: 0.2890625, loss: 3.782034397125244\n",
      "train step #34099 accuracy: 0.3046875, loss: 3.572955846786499\n",
      "train step #34199 accuracy: 0.25, loss: 4.013716697692871\n",
      "train step #34299 accuracy: 0.25, loss: 3.851287603378296\n",
      "train step #34399 accuracy: 0.28125, loss: 3.8019778728485107\n",
      "train step #34499 accuracy: 0.25, loss: 3.8620691299438477\n",
      "train step #34599 accuracy: 0.2578125, loss: 4.007001876831055\n",
      "train step #34699 accuracy: 0.328125, loss: 3.7300333976745605\n",
      "train step #34799 accuracy: 0.2734375, loss: 3.8908214569091797\n",
      "epoch #36, final dev accuracy: 0.2664751059322034\n",
      "train step #34899 accuracy: 0.2734375, loss: 3.756072521209717\n",
      "train step #34999 accuracy: 0.2578125, loss: 3.73384952545166\n",
      "train step #35099 accuracy: 0.265625, loss: 3.9795656204223633\n",
      "train step #35199 accuracy: 0.28125, loss: 3.8650825023651123\n",
      "train step #35299 accuracy: 0.2734375, loss: 3.900724411010742\n",
      "train step #35399 accuracy: 0.296875, loss: 3.650524139404297\n",
      "train step #35499 accuracy: 0.28125, loss: 3.5862624645233154\n",
      "train step #35599 accuracy: 0.2890625, loss: 3.8875696659088135\n",
      "train step #35699 accuracy: 0.25, loss: 3.971858263015747\n",
      "epoch #37, final dev accuracy: 0.27137447033898304\n",
      "train step #35799 accuracy: 0.234375, loss: 4.022262096405029\n",
      "train step #35899 accuracy: 0.34375, loss: 3.6690902709960938\n",
      "train step #35999 accuracy: 0.21875, loss: 4.021947383880615\n",
      "train step #36099 accuracy: 0.3203125, loss: 3.6945395469665527\n",
      "train step #36199 accuracy: 0.265625, loss: 3.8692679405212402\n",
      "train step #36299 accuracy: 0.28125, loss: 3.987238645553589\n",
      "train step #36399 accuracy: 0.2421875, loss: 3.615647554397583\n",
      "train step #36499 accuracy: 0.2109375, loss: 3.9111459255218506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #36599 accuracy: 0.3046875, loss: 3.7294676303863525\n",
      "train step #36699 accuracy: 0.2890625, loss: 3.8033111095428467\n",
      "epoch #38, final dev accuracy: 0.26854608050847456\n",
      "train step #36799 accuracy: 0.2890625, loss: 3.761760711669922\n",
      "train step #36899 accuracy: 0.28125, loss: 3.937309980392456\n",
      "train step #36999 accuracy: 0.328125, loss: 3.5092391967773438\n",
      "train step #37099 accuracy: 0.28125, loss: 3.8628756999969482\n",
      "train step #37199 accuracy: 0.2265625, loss: 3.8205888271331787\n",
      "train step #37299 accuracy: 0.21875, loss: 4.19265079498291\n",
      "train step #37399 accuracy: 0.2734375, loss: 4.145400524139404\n",
      "train step #37499 accuracy: 0.2890625, loss: 3.840805768966675\n",
      "train step #37599 accuracy: 0.265625, loss: 3.975008249282837\n",
      "epoch #39, final dev accuracy: 0.26949152542372884\n",
      "train step #37699 accuracy: 0.2734375, loss: 4.018747806549072\n",
      "train step #37799 accuracy: 0.25, loss: 4.09405517578125\n",
      "train step #37899 accuracy: 0.28125, loss: 3.718904972076416\n",
      "train step #37999 accuracy: 0.328125, loss: 3.4525554180145264\n",
      "train step #38099 accuracy: 0.25, loss: 3.9699504375457764\n",
      "train step #38199 accuracy: 0.21875, loss: 4.006070137023926\n",
      "train step #38299 accuracy: 0.3203125, loss: 3.8205626010894775\n",
      "train step #38399 accuracy: 0.1796875, loss: 4.146296501159668\n",
      "train step #38499 accuracy: 0.2890625, loss: 3.813436269760132\n",
      "train step #38599 accuracy: 0.265625, loss: 3.8115832805633545\n",
      "epoch #40, final dev accuracy: 0.2673278601694915\n",
      "train step #38699 accuracy: 0.2734375, loss: 3.9710514545440674\n",
      "train step #38799 accuracy: 0.2890625, loss: 3.5881898403167725\n",
      "train step #38899 accuracy: 0.265625, loss: 3.8430864810943604\n",
      "train step #38999 accuracy: 0.3125, loss: 3.674269914627075\n",
      "train step #39099 accuracy: 0.2734375, loss: 3.679499387741089\n",
      "train step #39199 accuracy: 0.3125, loss: 3.9123435020446777\n",
      "train step #39299 accuracy: 0.2734375, loss: 3.7968831062316895\n",
      "train step #39399 accuracy: 0.265625, loss: 3.9781789779663086\n",
      "train step #39499 accuracy: 0.296875, loss: 3.728584051132202\n",
      "epoch #41, final dev accuracy: 0.26907574152542374\n",
      "train step #39599 accuracy: 0.234375, loss: 3.9490528106689453\n",
      "train step #39699 accuracy: 0.28125, loss: 3.651691198348999\n",
      "train step #39799 accuracy: 0.28125, loss: 3.832723617553711\n",
      "train step #39899 accuracy: 0.2578125, loss: 3.908527135848999\n",
      "train step #39999 accuracy: 0.2578125, loss: 4.096802234649658\n",
      "train step #40099 accuracy: 0.3046875, loss: 3.653099536895752\n",
      "train step #40199 accuracy: 0.3125, loss: 3.7470388412475586\n",
      "train step #40299 accuracy: 0.3046875, loss: 3.6596310138702393\n",
      "train step #40399 accuracy: 0.3125, loss: 3.781797409057617\n",
      "train step #40499 accuracy: 0.3046875, loss: 3.757401943206787\n",
      "epoch #42, final dev accuracy: 0.2746477754237288\n",
      "saving best model...\n",
      "train step #40599 accuracy: 0.3046875, loss: 3.4396255016326904\n",
      "train step #40699 accuracy: 0.25, loss: 3.8903629779815674\n",
      "train step #40799 accuracy: 0.1796875, loss: 4.154636383056641\n",
      "train step #40899 accuracy: 0.3125, loss: 3.8139357566833496\n",
      "train step #40999 accuracy: 0.203125, loss: 3.9469430446624756\n",
      "train step #41099 accuracy: 0.2421875, loss: 4.0319318771362305\n",
      "train step #41199 accuracy: 0.296875, loss: 3.8198323249816895\n",
      "train step #41299 accuracy: 0.2109375, loss: 4.073507308959961\n",
      "train step #41399 accuracy: 0.234375, loss: 3.9288077354431152\n",
      "epoch #43, final dev accuracy: 0.2656726694915254\n",
      "train step #41499 accuracy: 0.3359375, loss: 3.539212226867676\n",
      "train step #41599 accuracy: 0.2734375, loss: 4.016650199890137\n",
      "train step #41699 accuracy: 0.28125, loss: 3.6860713958740234\n",
      "train step #41799 accuracy: 0.265625, loss: 4.004003047943115\n",
      "train step #41899 accuracy: 0.328125, loss: 3.5487215518951416\n",
      "train step #41999 accuracy: 0.34375, loss: 3.7095212936401367\n",
      "train step #42099 accuracy: 0.3046875, loss: 3.6550827026367188\n",
      "train step #42199 accuracy: 0.3125, loss: 3.888004779815674\n",
      "train step #42299 accuracy: 0.21875, loss: 4.227074146270752\n",
      "epoch #44, final dev accuracy: 0.27540254237288136\n",
      "saving best model...\n",
      "train step #42399 accuracy: 0.25, loss: 3.8943982124328613\n",
      "train step #42499 accuracy: 0.21875, loss: 3.9423420429229736\n",
      "train step #42599 accuracy: 0.21875, loss: 3.896099328994751\n",
      "train step #42699 accuracy: 0.25, loss: 3.990572214126587\n",
      "train step #42799 accuracy: 0.21875, loss: 4.127659320831299\n",
      "train step #42899 accuracy: 0.28125, loss: 4.059164047241211\n",
      "train step #42999 accuracy: 0.3125, loss: 3.5772736072540283\n",
      "train step #43099 accuracy: 0.2421875, loss: 4.056522369384766\n",
      "train step #43199 accuracy: 0.3359375, loss: 3.5221550464630127\n",
      "train step #43299 accuracy: 0.21875, loss: 4.202853679656982\n",
      "epoch #45, final dev accuracy: 0.27124205508474575\n",
      "train step #43399 accuracy: 0.328125, loss: 3.6546847820281982\n",
      "train step #43499 accuracy: 0.28125, loss: 3.923081398010254\n",
      "train step #43599 accuracy: 0.296875, loss: 3.608088731765747\n",
      "train step #43699 accuracy: 0.28125, loss: 3.821094274520874\n",
      "train step #43799 accuracy: 0.2421875, loss: 3.902705192565918\n",
      "train step #43899 accuracy: 0.296875, loss: 3.8748817443847656\n",
      "train step #43999 accuracy: 0.2890625, loss: 4.017385482788086\n",
      "train step #44099 accuracy: 0.2578125, loss: 3.8808350563049316\n",
      "train step #44199 accuracy: 0.2890625, loss: 3.5974442958831787\n",
      "epoch #46, final dev accuracy: 0.27511917372881356\n",
      "train step #44299 accuracy: 0.265625, loss: 3.970217704772949\n",
      "train step #44399 accuracy: 0.2421875, loss: 3.878419876098633\n",
      "train step #44499 accuracy: 0.3046875, loss: 3.717144250869751\n",
      "train step #44599 accuracy: 0.28125, loss: 3.89652419090271\n",
      "train step #44699 accuracy: 0.2421875, loss: 3.7589011192321777\n",
      "train step #44799 accuracy: 0.2890625, loss: 3.8469960689544678\n",
      "train step #44899 accuracy: 0.2421875, loss: 3.812279224395752\n",
      "train step #44999 accuracy: 0.3046875, loss: 3.655369758605957\n",
      "train step #45099 accuracy: 0.234375, loss: 3.9602859020233154\n",
      "train step #45199 accuracy: 0.2421875, loss: 3.8892273902893066\n",
      "epoch #47, final dev accuracy: 0.2749973516949153\n",
      "train step #45299 accuracy: 0.28125, loss: 3.9357762336730957\n",
      "train step #45399 accuracy: 0.2578125, loss: 4.043540954589844\n",
      "train step #45499 accuracy: 0.3359375, loss: 3.541814088821411\n",
      "train step #45599 accuracy: 0.2890625, loss: 3.8407859802246094\n",
      "train step #45699 accuracy: 0.328125, loss: 3.620759963989258\n",
      "train step #45799 accuracy: 0.2578125, loss: 3.9162914752960205\n",
      "train step #45899 accuracy: 0.2734375, loss: 3.8553903102874756\n",
      "train step #45999 accuracy: 0.328125, loss: 3.568707227706909\n",
      "train step #46099 accuracy: 0.2734375, loss: 4.034650802612305\n",
      "epoch #48, final dev accuracy: 0.27443855932203387\n",
      "train step #46199 accuracy: 0.25, loss: 3.7611312866210938\n",
      "train step #46299 accuracy: 0.2734375, loss: 3.903783082962036\n",
      "train step #46399 accuracy: 0.3046875, loss: 3.6079659461975098\n",
      "train step #46499 accuracy: 0.2890625, loss: 3.8155007362365723\n",
      "train step #46599 accuracy: 0.2734375, loss: 3.864804267883301\n",
      "train step #46699 accuracy: 0.3515625, loss: 3.455002784729004\n",
      "train step #46799 accuracy: 0.3046875, loss: 3.7476963996887207\n",
      "train step #46899 accuracy: 0.203125, loss: 4.242459774017334\n",
      "train step #46999 accuracy: 0.2578125, loss: 3.9780433177948\n",
      "train step #47099 accuracy: 0.2890625, loss: 3.8866984844207764\n",
      "epoch #49, final dev accuracy: 0.27558262711864406\n",
      "saving best model...\n",
      "train step #47199 accuracy: 0.3125, loss: 3.7522566318511963\n",
      "train step #47299 accuracy: 0.328125, loss: 3.6876304149627686\n",
      "train step #47399 accuracy: 0.140625, loss: 4.289774417877197\n",
      "train step #47499 accuracy: 0.21875, loss: 4.056589126586914\n",
      "train step #47599 accuracy: 0.2578125, loss: 3.871823787689209\n",
      "train step #47699 accuracy: 0.2890625, loss: 3.900273323059082\n",
      "train step #47799 accuracy: 0.2734375, loss: 3.920015335083008\n",
      "train step #47899 accuracy: 0.2890625, loss: 3.840421438217163\n",
      "train step #47999 accuracy: 0.3046875, loss: 3.745565891265869\n",
      "epoch #50, final dev accuracy: 0.2764830508474576\n",
      "saving best model...\n",
      "train step #48099 accuracy: 0.2578125, loss: 3.97062611579895\n",
      "train step #48199 accuracy: 0.3125, loss: 3.7007558345794678\n",
      "train step #48299 accuracy: 0.25, loss: 4.161212921142578\n",
      "train step #48399 accuracy: 0.2734375, loss: 4.041762351989746\n",
      "train step #48499 accuracy: 0.234375, loss: 3.7463412284851074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #48599 accuracy: 0.3125, loss: 3.6619207859039307\n",
      "train step #48699 accuracy: 0.28125, loss: 3.7151310443878174\n",
      "train step #48799 accuracy: 0.2734375, loss: 3.7996740341186523\n",
      "train step #48899 accuracy: 0.203125, loss: 3.8925294876098633\n",
      "epoch #51, final dev accuracy: 0.27728548728813557\n",
      "saving best model...\n",
      "train step #48999 accuracy: 0.296875, loss: 3.8892128467559814\n",
      "train step #49099 accuracy: 0.25, loss: 3.8863439559936523\n",
      "train step #49199 accuracy: 0.328125, loss: 3.5202481746673584\n",
      "train step #49299 accuracy: 0.2421875, loss: 3.956813097000122\n",
      "train step #49399 accuracy: 0.296875, loss: 3.813704490661621\n",
      "train step #49499 accuracy: 0.3046875, loss: 3.7541534900665283\n",
      "train step #49599 accuracy: 0.25, loss: 3.846198558807373\n",
      "train step #49699 accuracy: 0.3125, loss: 3.792560577392578\n",
      "train step #49799 accuracy: 0.25, loss: 3.8326892852783203\n",
      "train step #49899 accuracy: 0.34375, loss: 3.5940921306610107\n",
      "epoch #52, final dev accuracy: 0.2783845338983051\n",
      "saving best model...\n",
      "train step #49999 accuracy: 0.3046875, loss: 3.6395909786224365\n",
      "train step #50099 accuracy: 0.234375, loss: 3.9467720985412598\n",
      "train step #50199 accuracy: 0.2734375, loss: 3.692911148071289\n",
      "train step #50299 accuracy: 0.265625, loss: 3.8529279232025146\n",
      "train step #50399 accuracy: 0.265625, loss: 3.832327127456665\n",
      "train step #50499 accuracy: 0.3125, loss: 3.721712589263916\n",
      "train step #50599 accuracy: 0.28125, loss: 3.9892783164978027\n",
      "train step #50699 accuracy: 0.3046875, loss: 3.856252670288086\n",
      "train step #50799 accuracy: 0.328125, loss: 3.527862071990967\n",
      "epoch #53, final dev accuracy: 0.2726509533898305\n",
      "train step #50899 accuracy: 0.3203125, loss: 3.5671019554138184\n",
      "train step #50999 accuracy: 0.328125, loss: 3.6506779193878174\n",
      "train step #51099 accuracy: 0.28125, loss: 3.5455150604248047\n",
      "train step #51199 accuracy: 0.328125, loss: 3.5352258682250977\n",
      "train step #51299 accuracy: 0.2578125, loss: 3.6660215854644775\n",
      "train step #51399 accuracy: 0.3828125, loss: 3.4423270225524902\n",
      "train step #51499 accuracy: 0.2421875, loss: 3.955686092376709\n",
      "train step #51599 accuracy: 0.328125, loss: 3.7495999336242676\n",
      "train step #51699 accuracy: 0.2578125, loss: 4.027836799621582\n",
      "train step #51799 accuracy: 0.296875, loss: 3.5780951976776123\n",
      "epoch #54, final dev accuracy: 0.2747113347457627\n",
      "train step #51899 accuracy: 0.28125, loss: 3.817744016647339\n",
      "train step #51999 accuracy: 0.2109375, loss: 4.0369720458984375\n",
      "train step #52099 accuracy: 0.296875, loss: 3.886324405670166\n",
      "train step #52199 accuracy: 0.3046875, loss: 3.8930277824401855\n",
      "train step #52299 accuracy: 0.25, loss: 3.9528231620788574\n",
      "train step #52399 accuracy: 0.2734375, loss: 3.621971368789673\n",
      "train step #52499 accuracy: 0.2734375, loss: 3.7066397666931152\n",
      "train step #52599 accuracy: 0.328125, loss: 3.6221272945404053\n",
      "train step #52699 accuracy: 0.3125, loss: 3.6427063941955566\n",
      "epoch #55, final dev accuracy: 0.27668961864406777\n",
      "train step #52799 accuracy: 0.34375, loss: 3.5305607318878174\n",
      "train step #52899 accuracy: 0.234375, loss: 3.9645769596099854\n",
      "train step #52999 accuracy: 0.2890625, loss: 3.6472299098968506\n",
      "train step #53099 accuracy: 0.2734375, loss: 3.954116106033325\n",
      "train step #53199 accuracy: 0.296875, loss: 3.62241792678833\n",
      "train step #53299 accuracy: 0.328125, loss: 3.6607885360717773\n",
      "train step #53399 accuracy: 0.3515625, loss: 3.5860304832458496\n",
      "train step #53499 accuracy: 0.2421875, loss: 3.9584131240844727\n",
      "train step #53599 accuracy: 0.28125, loss: 3.714526653289795\n",
      "epoch #56, final dev accuracy: 0.2801244703389831\n",
      "saving best model...\n",
      "train step #53699 accuracy: 0.234375, loss: 4.013156890869141\n",
      "train step #53799 accuracy: 0.25, loss: 3.9308526515960693\n",
      "train step #53899 accuracy: 0.359375, loss: 3.727480173110962\n",
      "train step #53999 accuracy: 0.3671875, loss: 3.45686936378479\n",
      "train step #54099 accuracy: 0.28125, loss: 3.8677146434783936\n",
      "train step #54199 accuracy: 0.3515625, loss: 3.6760401725769043\n",
      "train step #54299 accuracy: 0.28125, loss: 3.849543333053589\n",
      "train step #54399 accuracy: 0.2421875, loss: 3.9128668308258057\n",
      "train step #54499 accuracy: 0.3203125, loss: 3.624835252761841\n",
      "train step #54599 accuracy: 0.25, loss: 3.8681328296661377\n",
      "epoch #57, final dev accuracy: 0.273718220338983\n",
      "train step #54699 accuracy: 0.296875, loss: 3.6077864170074463\n",
      "train step #54799 accuracy: 0.2734375, loss: 3.7995290756225586\n",
      "train step #54899 accuracy: 0.296875, loss: 3.6489295959472656\n",
      "train step #54999 accuracy: 0.25, loss: 3.7366881370544434\n",
      "train step #55099 accuracy: 0.34375, loss: 3.6875312328338623\n",
      "train step #55199 accuracy: 0.2578125, loss: 3.6738412380218506\n",
      "train step #55299 accuracy: 0.3203125, loss: 3.63602876663208\n",
      "train step #55399 accuracy: 0.25, loss: 3.8482871055603027\n",
      "train step #55499 accuracy: 0.21875, loss: 4.100931644439697\n",
      "epoch #58, final dev accuracy: 0.28023834745762716\n",
      "saving best model...\n",
      "train step #55599 accuracy: 0.3828125, loss: 3.7430005073547363\n",
      "train step #55699 accuracy: 0.3515625, loss: 3.51529860496521\n",
      "train step #55799 accuracy: 0.2421875, loss: 3.9987125396728516\n",
      "train step #55899 accuracy: 0.1875, loss: 3.8529815673828125\n",
      "train step #55999 accuracy: 0.2734375, loss: 3.8414700031280518\n",
      "train step #56099 accuracy: 0.265625, loss: 3.595888137817383\n",
      "train step #56199 accuracy: 0.3125, loss: 3.821932077407837\n",
      "train step #56299 accuracy: 0.2421875, loss: 4.138408184051514\n",
      "train step #56399 accuracy: 0.2578125, loss: 3.99807071685791\n",
      "train step #56499 accuracy: 0.2890625, loss: 3.6361708641052246\n",
      "epoch #59, final dev accuracy: 0.27545815677966107\n",
      "train step #56599 accuracy: 0.2734375, loss: 4.0440754890441895\n",
      "train step #56699 accuracy: 0.3359375, loss: 3.5208423137664795\n",
      "train step #56799 accuracy: 0.3671875, loss: 3.6845450401306152\n",
      "train step #56899 accuracy: 0.359375, loss: 3.5543835163116455\n",
      "train step #56999 accuracy: 0.234375, loss: 3.808438539505005\n",
      "train step #57099 accuracy: 0.3828125, loss: 3.4840502738952637\n",
      "train step #57199 accuracy: 0.3203125, loss: 3.7264950275421143\n",
      "train step #57299 accuracy: 0.2578125, loss: 3.783900260925293\n",
      "train step #57399 accuracy: 0.265625, loss: 3.9947922229766846\n",
      "epoch #60, final dev accuracy: 0.2763135593220339\n",
      "train step #57499 accuracy: 0.359375, loss: 3.581491470336914\n",
      "train step #57599 accuracy: 0.265625, loss: 3.8215513229370117\n",
      "train step #57699 accuracy: 0.25, loss: 4.092936992645264\n",
      "train step #57799 accuracy: 0.2578125, loss: 3.777811288833618\n",
      "train step #57899 accuracy: 0.28125, loss: 3.712838888168335\n",
      "train step #57999 accuracy: 0.296875, loss: 3.78657865524292\n",
      "train step #58099 accuracy: 0.3046875, loss: 3.7635655403137207\n",
      "train step #58199 accuracy: 0.28125, loss: 3.7656726837158203\n",
      "train step #58299 accuracy: 0.34375, loss: 3.5728673934936523\n",
      "train step #58399 accuracy: 0.203125, loss: 4.143892288208008\n",
      "epoch #61, final dev accuracy: 0.2756514830508474\n",
      "train step #58499 accuracy: 0.2734375, loss: 3.7803385257720947\n",
      "train step #58599 accuracy: 0.2109375, loss: 3.8596696853637695\n",
      "train step #58699 accuracy: 0.296875, loss: 3.8851449489593506\n",
      "train step #58799 accuracy: 0.3359375, loss: 3.605487585067749\n",
      "train step #58899 accuracy: 0.2578125, loss: 3.833212375640869\n",
      "train step #58999 accuracy: 0.234375, loss: 3.8760650157928467\n",
      "train step #59099 accuracy: 0.3125, loss: 3.560608386993408\n",
      "train step #59199 accuracy: 0.2890625, loss: 3.599289655685425\n",
      "train step #59299 accuracy: 0.21875, loss: 4.115531921386719\n",
      "epoch #62, final dev accuracy: 0.2786837923728813\n",
      "train step #59399 accuracy: 0.2578125, loss: 3.8645734786987305\n",
      "train step #59499 accuracy: 0.3203125, loss: 3.738452672958374\n",
      "train step #59599 accuracy: 0.265625, loss: 3.6303844451904297\n",
      "train step #59699 accuracy: 0.2734375, loss: 3.8468775749206543\n",
      "train step #59799 accuracy: 0.3046875, loss: 3.712484359741211\n",
      "train step #59899 accuracy: 0.265625, loss: 4.029975891113281\n",
      "train step #59999 accuracy: 0.28125, loss: 3.8343405723571777\n",
      "train step #60099 accuracy: 0.2890625, loss: 3.7654454708099365\n",
      "train step #60199 accuracy: 0.3046875, loss: 3.7940659523010254\n",
      "epoch #63, final dev accuracy: 0.27652542372881356\n",
      "train step #60299 accuracy: 0.296875, loss: 3.9027345180511475\n",
      "train step #60399 accuracy: 0.34375, loss: 3.4546213150024414\n",
      "train step #60499 accuracy: 0.2734375, loss: 3.9596633911132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #60599 accuracy: 0.3515625, loss: 3.482417583465576\n",
      "train step #60699 accuracy: 0.2578125, loss: 3.9813244342803955\n",
      "train step #60799 accuracy: 0.3046875, loss: 3.71651554107666\n",
      "train step #60899 accuracy: 0.2890625, loss: 3.661346435546875\n",
      "train step #60999 accuracy: 0.3125, loss: 3.6197307109832764\n",
      "train step #61099 accuracy: 0.2734375, loss: 3.473804235458374\n",
      "train step #61199 accuracy: 0.3203125, loss: 3.6669673919677734\n",
      "epoch #64, final dev accuracy: 0.2787076271186441\n",
      "train step #61299 accuracy: 0.34375, loss: 3.572035789489746\n",
      "train step #61399 accuracy: 0.265625, loss: 3.719458818435669\n",
      "train step #61499 accuracy: 0.2734375, loss: 3.800983190536499\n",
      "train step #61599 accuracy: 0.296875, loss: 3.8815300464630127\n",
      "train step #61699 accuracy: 0.34375, loss: 3.6210944652557373\n",
      "train step #61799 accuracy: 0.2421875, loss: 3.9448256492614746\n",
      "train step #61899 accuracy: 0.3203125, loss: 3.6156692504882812\n",
      "train step #61999 accuracy: 0.2890625, loss: 3.8714473247528076\n",
      "train step #62099 accuracy: 0.3359375, loss: 3.427912473678589\n",
      "epoch #65, final dev accuracy: 0.28125794491525424\n",
      "saving best model...\n",
      "train step #62199 accuracy: 0.25, loss: 3.7273662090301514\n",
      "train step #62299 accuracy: 0.265625, loss: 3.919896364212036\n",
      "train step #62399 accuracy: 0.265625, loss: 3.8719213008880615\n",
      "train step #62499 accuracy: 0.25, loss: 4.132411956787109\n",
      "train step #62599 accuracy: 0.3203125, loss: 3.69031023979187\n",
      "train step #62699 accuracy: 0.25, loss: 3.946537733078003\n",
      "train step #62799 accuracy: 0.265625, loss: 3.789153814315796\n",
      "train step #62899 accuracy: 0.3203125, loss: 3.734363317489624\n",
      "train step #62999 accuracy: 0.3125, loss: 3.691094160079956\n",
      "train step #63099 accuracy: 0.3125, loss: 3.604616403579712\n",
      "epoch #66, final dev accuracy: 0.28404925847457624\n",
      "saving best model...\n",
      "train step #63199 accuracy: 0.296875, loss: 3.6086246967315674\n",
      "train step #63299 accuracy: 0.234375, loss: 3.8496673107147217\n",
      "train step #63399 accuracy: 0.2109375, loss: 4.102189540863037\n",
      "train step #63499 accuracy: 0.2890625, loss: 3.834902763366699\n",
      "train step #63599 accuracy: 0.2890625, loss: 3.7682251930236816\n",
      "train step #63699 accuracy: 0.25, loss: 3.9368162155151367\n",
      "train step #63799 accuracy: 0.3125, loss: 3.737544536590576\n",
      "train step #63899 accuracy: 0.28125, loss: 3.7984073162078857\n",
      "train step #63999 accuracy: 0.2890625, loss: 3.553266763687134\n",
      "epoch #67, final dev accuracy: 0.281239406779661\n",
      "train step #64099 accuracy: 0.3828125, loss: 3.5267224311828613\n",
      "train step #64199 accuracy: 0.3125, loss: 3.7491202354431152\n",
      "train step #64299 accuracy: 0.2578125, loss: 3.624516248703003\n",
      "train step #64399 accuracy: 0.2265625, loss: 4.00393009185791\n",
      "train step #64499 accuracy: 0.3046875, loss: 3.613840341567993\n",
      "train step #64599 accuracy: 0.3359375, loss: 3.512979030609131\n",
      "train step #64699 accuracy: 0.2734375, loss: 3.803032398223877\n",
      "train step #64799 accuracy: 0.2890625, loss: 3.5987744331359863\n",
      "train step #64899 accuracy: 0.2578125, loss: 3.799079656600952\n",
      "epoch #68, final dev accuracy: 0.2777039194915254\n",
      "train step #64999 accuracy: 0.2890625, loss: 3.8468494415283203\n",
      "train step #65099 accuracy: 0.390625, loss: 3.5117225646972656\n",
      "train step #65199 accuracy: 0.2890625, loss: 3.6161530017852783\n",
      "train step #65299 accuracy: 0.3046875, loss: 3.8328890800476074\n",
      "train step #65399 accuracy: 0.3203125, loss: 3.6782643795013428\n",
      "train step #65499 accuracy: 0.2890625, loss: 3.690706968307495\n",
      "train step #65599 accuracy: 0.2734375, loss: 3.7007951736450195\n",
      "train step #65699 accuracy: 0.234375, loss: 4.00776481628418\n",
      "train step #65799 accuracy: 0.2578125, loss: 3.7875473499298096\n",
      "train step #65899 accuracy: 0.3046875, loss: 3.702186346054077\n",
      "epoch #69, final dev accuracy: 0.2825926906779661\n",
      "train step #65999 accuracy: 0.21875, loss: 4.190810680389404\n",
      "train step #66099 accuracy: 0.25, loss: 3.9159088134765625\n",
      "train step #66199 accuracy: 0.2890625, loss: 3.7592453956604004\n",
      "train step #66299 accuracy: 0.3359375, loss: 3.5166335105895996\n",
      "train step #66399 accuracy: 0.296875, loss: 3.758941173553467\n",
      "train step #66499 accuracy: 0.3515625, loss: 3.303842544555664\n",
      "train step #66599 accuracy: 0.2578125, loss: 3.9074926376342773\n",
      "train step #66699 accuracy: 0.2734375, loss: 3.699756383895874\n",
      "train step #66799 accuracy: 0.328125, loss: 3.793898344039917\n",
      "epoch #70, final dev accuracy: 0.28546875\n",
      "saving best model...\n",
      "train step #66899 accuracy: 0.3515625, loss: 3.547697067260742\n",
      "train step #66999 accuracy: 0.265625, loss: 3.808539390563965\n",
      "train step #67099 accuracy: 0.234375, loss: 3.755814552307129\n",
      "train step #67199 accuracy: 0.28125, loss: 3.9256718158721924\n",
      "train step #67299 accuracy: 0.3203125, loss: 3.7624804973602295\n",
      "train step #67399 accuracy: 0.2265625, loss: 3.9464268684387207\n",
      "train step #67499 accuracy: 0.25, loss: 3.787658452987671\n",
      "train step #67599 accuracy: 0.28125, loss: 3.610354423522949\n",
      "train step #67699 accuracy: 0.2890625, loss: 3.783872604370117\n",
      "train step #67799 accuracy: 0.2890625, loss: 3.917444944381714\n",
      "epoch #71, final dev accuracy: 0.2838135593220339\n",
      "train step #67899 accuracy: 0.296875, loss: 3.7542123794555664\n",
      "train step #67999 accuracy: 0.2734375, loss: 3.80100154876709\n",
      "train step #68099 accuracy: 0.2578125, loss: 3.7927796840667725\n",
      "train step #68199 accuracy: 0.2890625, loss: 3.732089042663574\n",
      "train step #68299 accuracy: 0.3125, loss: 3.6379706859588623\n",
      "train step #68399 accuracy: 0.375, loss: 3.4317541122436523\n",
      "train step #68499 accuracy: 0.3203125, loss: 3.6279778480529785\n",
      "train step #68599 accuracy: 0.296875, loss: 3.7571165561676025\n",
      "train step #68699 accuracy: 0.28125, loss: 3.818516969680786\n",
      "epoch #72, final dev accuracy: 0.2815995762711864\n",
      "train step #68799 accuracy: 0.25, loss: 4.025436878204346\n",
      "train step #68899 accuracy: 0.2890625, loss: 3.6525230407714844\n",
      "train step #68999 accuracy: 0.25, loss: 3.843649387359619\n",
      "train step #69099 accuracy: 0.3515625, loss: 3.5387072563171387\n",
      "train step #69199 accuracy: 0.234375, loss: 3.865842342376709\n",
      "train step #69299 accuracy: 0.2734375, loss: 3.8583877086639404\n",
      "train step #69399 accuracy: 0.3046875, loss: 3.621476411819458\n",
      "train step #69499 accuracy: 0.3203125, loss: 3.5589704513549805\n",
      "train step #69599 accuracy: 0.25, loss: 3.898428440093994\n",
      "train step #69699 accuracy: 0.3203125, loss: 3.774195671081543\n",
      "epoch #73, final dev accuracy: 0.2801853813559322\n",
      "train step #69799 accuracy: 0.3203125, loss: 3.69646954536438\n",
      "train step #69899 accuracy: 0.2734375, loss: 3.8524727821350098\n",
      "train step #69999 accuracy: 0.3125, loss: 3.6693098545074463\n",
      "train step #70099 accuracy: 0.3125, loss: 3.891828775405884\n",
      "train step #70199 accuracy: 0.3203125, loss: 3.8609743118286133\n",
      "train step #70299 accuracy: 0.3515625, loss: 3.4495253562927246\n",
      "train step #70399 accuracy: 0.359375, loss: 3.5181760787963867\n",
      "train step #70499 accuracy: 0.296875, loss: 3.841585159301758\n",
      "train step #70599 accuracy: 0.3203125, loss: 3.6960525512695312\n",
      "epoch #74, final dev accuracy: 0.28001059322033894\n",
      "train step #70699 accuracy: 0.265625, loss: 3.9576938152313232\n",
      "train step #70799 accuracy: 0.2734375, loss: 3.99043345451355\n",
      "train step #70899 accuracy: 0.265625, loss: 3.932997226715088\n",
      "train step #70999 accuracy: 0.296875, loss: 3.688101291656494\n",
      "train step #71099 accuracy: 0.2734375, loss: 3.997720241546631\n",
      "train step #71199 accuracy: 0.3046875, loss: 3.8738203048706055\n",
      "train step #71299 accuracy: 0.265625, loss: 4.023090362548828\n",
      "train step #71399 accuracy: 0.296875, loss: 3.9361026287078857\n",
      "train step #71499 accuracy: 0.359375, loss: 3.448788642883301\n",
      "epoch #75, final dev accuracy: 0.29080243644067794\n",
      "saving best model...\n",
      "train step #71599 accuracy: 0.265625, loss: 4.074106216430664\n",
      "train step #71699 accuracy: 0.28125, loss: 3.766970634460449\n",
      "train step #71799 accuracy: 0.265625, loss: 3.798746347427368\n",
      "train step #71899 accuracy: 0.28125, loss: 3.80047869682312\n",
      "train step #71999 accuracy: 0.3359375, loss: 3.685992479324341\n",
      "train step #72099 accuracy: 0.2578125, loss: 3.901960611343384\n",
      "train step #72199 accuracy: 0.3203125, loss: 3.589247465133667\n",
      "train step #72299 accuracy: 0.171875, loss: 4.179562091827393\n",
      "train step #72399 accuracy: 0.1953125, loss: 4.138439655303955\n",
      "train step #72499 accuracy: 0.2421875, loss: 4.006338119506836\n",
      "epoch #76, final dev accuracy: 0.28784957627118646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #72599 accuracy: 0.3203125, loss: 3.6387009620666504\n",
      "train step #72699 accuracy: 0.3515625, loss: 3.440981864929199\n",
      "train step #72799 accuracy: 0.3203125, loss: 3.5809199810028076\n",
      "train step #72899 accuracy: 0.296875, loss: 3.6013741493225098\n",
      "train step #72999 accuracy: 0.34375, loss: 3.510887861251831\n",
      "train step #73099 accuracy: 0.234375, loss: 4.025882720947266\n",
      "train step #73199 accuracy: 0.234375, loss: 3.837940216064453\n",
      "train step #73299 accuracy: 0.375, loss: 3.5096237659454346\n",
      "train step #73399 accuracy: 0.2265625, loss: 3.817394495010376\n",
      "epoch #77, final dev accuracy: 0.2819782838983051\n",
      "train step #73499 accuracy: 0.3359375, loss: 3.5605082511901855\n",
      "train step #73599 accuracy: 0.296875, loss: 3.651632308959961\n",
      "train step #73699 accuracy: 0.3359375, loss: 3.7000045776367188\n",
      "train step #73799 accuracy: 0.3203125, loss: 3.484530448913574\n",
      "train step #73899 accuracy: 0.34375, loss: 3.641610622406006\n",
      "train step #73999 accuracy: 0.265625, loss: 3.9335546493530273\n",
      "train step #74099 accuracy: 0.234375, loss: 4.040861129760742\n",
      "train step #74199 accuracy: 0.3671875, loss: 3.5533840656280518\n",
      "train step #74299 accuracy: 0.2890625, loss: 3.860377073287964\n",
      "train step #74399 accuracy: 0.171875, loss: 4.323741912841797\n",
      "epoch #78, final dev accuracy: 0.286583686440678\n",
      "train step #74499 accuracy: 0.3046875, loss: 3.4502694606781006\n",
      "train step #74599 accuracy: 0.296875, loss: 3.694066047668457\n",
      "train step #74699 accuracy: 0.3046875, loss: 3.4357619285583496\n",
      "train step #74799 accuracy: 0.3359375, loss: 3.6206600666046143\n",
      "train step #74899 accuracy: 0.3125, loss: 3.589810848236084\n",
      "train step #74999 accuracy: 0.28125, loss: 3.669599771499634\n",
      "train step #75099 accuracy: 0.296875, loss: 3.8494603633880615\n",
      "train step #75199 accuracy: 0.3125, loss: 3.541504144668579\n",
      "train step #75299 accuracy: 0.328125, loss: 3.757052421569824\n",
      "epoch #79, final dev accuracy: 0.2897590042372882\n",
      "train step #75399 accuracy: 0.2890625, loss: 3.4859330654144287\n",
      "train step #75499 accuracy: 0.3828125, loss: 3.582548141479492\n",
      "train step #75599 accuracy: 0.2734375, loss: 3.742436170578003\n",
      "train step #75699 accuracy: 0.3203125, loss: 3.5745484828948975\n",
      "train step #75799 accuracy: 0.2890625, loss: 3.7988038063049316\n",
      "train step #75899 accuracy: 0.2109375, loss: 4.205219745635986\n",
      "train step #75999 accuracy: 0.2890625, loss: 3.6991894245147705\n",
      "train step #76099 accuracy: 0.3046875, loss: 3.681295394897461\n",
      "train step #76199 accuracy: 0.28125, loss: 3.6522510051727295\n",
      "train step #76299 accuracy: 0.2734375, loss: 3.7565419673919678\n",
      "epoch #80, final dev accuracy: 0.28884269067796614\n",
      "train step #76399 accuracy: 0.2734375, loss: 3.733250617980957\n",
      "train step #76499 accuracy: 0.3984375, loss: 3.567519187927246\n",
      "train step #76599 accuracy: 0.3125, loss: 3.6396851539611816\n",
      "train step #76699 accuracy: 0.3359375, loss: 3.7881059646606445\n",
      "train step #76799 accuracy: 0.2109375, loss: 4.016030311584473\n",
      "train step #76899 accuracy: 0.2890625, loss: 3.70829176902771\n",
      "train step #76999 accuracy: 0.3203125, loss: 3.746509552001953\n",
      "train step #77099 accuracy: 0.265625, loss: 3.7795028686523438\n",
      "train step #77199 accuracy: 0.296875, loss: 3.810462474822998\n",
      "epoch #81, final dev accuracy: 0.28529661016949154\n",
      "train step #77299 accuracy: 0.3125, loss: 3.599320650100708\n",
      "train step #77399 accuracy: 0.2421875, loss: 3.8087306022644043\n",
      "train step #77499 accuracy: 0.2421875, loss: 4.000319004058838\n",
      "train step #77599 accuracy: 0.3046875, loss: 3.5735766887664795\n",
      "train step #77699 accuracy: 0.328125, loss: 3.694869041442871\n",
      "train step #77799 accuracy: 0.2890625, loss: 4.018261432647705\n",
      "train step #77899 accuracy: 0.2890625, loss: 3.726419687271118\n",
      "train step #77999 accuracy: 0.2578125, loss: 3.7628731727600098\n",
      "train step #78099 accuracy: 0.3046875, loss: 3.724720001220703\n",
      "epoch #82, final dev accuracy: 0.27983845338983054\n",
      "train step #78199 accuracy: 0.265625, loss: 3.6128013134002686\n",
      "train step #78299 accuracy: 0.3515625, loss: 3.3791122436523438\n",
      "train step #78399 accuracy: 0.3984375, loss: 3.351041555404663\n",
      "train step #78499 accuracy: 0.3046875, loss: 3.639225482940674\n",
      "train step #78599 accuracy: 0.3125, loss: 3.6249003410339355\n",
      "train step #78699 accuracy: 0.25, loss: 4.009471416473389\n",
      "train step #78799 accuracy: 0.3359375, loss: 3.6715149879455566\n",
      "train step #78899 accuracy: 0.296875, loss: 3.7400319576263428\n",
      "train step #78999 accuracy: 0.3046875, loss: 3.759176015853882\n",
      "train step #79099 accuracy: 0.3359375, loss: 3.5225613117218018\n",
      "epoch #83, final dev accuracy: 0.2879369703389831\n",
      "train step #79199 accuracy: 0.265625, loss: 3.8370652198791504\n",
      "train step #79299 accuracy: 0.328125, loss: 3.6263670921325684\n",
      "train step #79399 accuracy: 0.3203125, loss: 3.5556094646453857\n",
      "train step #79499 accuracy: 0.3125, loss: 3.616128921508789\n",
      "train step #79599 accuracy: 0.3359375, loss: 3.530550241470337\n",
      "train step #79699 accuracy: 0.28125, loss: 3.7633118629455566\n",
      "train step #79799 accuracy: 0.359375, loss: 3.677448034286499\n",
      "train step #79899 accuracy: 0.234375, loss: 3.9886746406555176\n",
      "train step #79999 accuracy: 0.328125, loss: 3.370457410812378\n",
      "epoch #84, final dev accuracy: 0.2867161016949153\n",
      "train step #80099 accuracy: 0.34375, loss: 3.519120216369629\n",
      "train step #80199 accuracy: 0.2421875, loss: 3.825406551361084\n",
      "train step #80299 accuracy: 0.296875, loss: 3.548398971557617\n",
      "train step #80399 accuracy: 0.21875, loss: 3.920119047164917\n",
      "train step #80499 accuracy: 0.3125, loss: 3.6907293796539307\n",
      "train step #80599 accuracy: 0.3359375, loss: 3.6423211097717285\n",
      "train step #80699 accuracy: 0.265625, loss: 3.839564085006714\n",
      "train step #80799 accuracy: 0.3359375, loss: 3.7686195373535156\n",
      "train step #80899 accuracy: 0.3203125, loss: 3.644867420196533\n",
      "train step #80999 accuracy: 0.265625, loss: 4.050872802734375\n",
      "epoch #85, final dev accuracy: 0.2879634533898305\n",
      "train step #81099 accuracy: 0.3046875, loss: 3.70495867729187\n",
      "train step #81199 accuracy: 0.2109375, loss: 3.9478564262390137\n",
      "train step #81299 accuracy: 0.21875, loss: 4.062140941619873\n",
      "train step #81399 accuracy: 0.3046875, loss: 3.6726744174957275\n",
      "train step #81499 accuracy: 0.3203125, loss: 3.5996956825256348\n",
      "train step #81599 accuracy: 0.3046875, loss: 3.781100273132324\n",
      "train step #81699 accuracy: 0.328125, loss: 3.64945650100708\n",
      "train step #81799 accuracy: 0.328125, loss: 3.77583384513855\n",
      "train step #81899 accuracy: 0.265625, loss: 3.6844751834869385\n",
      "epoch #86, final dev accuracy: 0.2883633474576271\n",
      "train step #81999 accuracy: 0.2421875, loss: 3.8240725994110107\n",
      "train step #82099 accuracy: 0.28125, loss: 3.7902302742004395\n",
      "train step #82199 accuracy: 0.3515625, loss: 3.5049524307250977\n",
      "train step #82299 accuracy: 0.2890625, loss: 3.583390712738037\n",
      "train step #82399 accuracy: 0.2578125, loss: 3.8714511394500732\n",
      "train step #82499 accuracy: 0.328125, loss: 3.523082971572876\n",
      "train step #82599 accuracy: 0.2890625, loss: 3.726869821548462\n",
      "train step #82699 accuracy: 0.3203125, loss: 3.749448537826538\n",
      "train step #82799 accuracy: 0.3515625, loss: 3.5261335372924805\n",
      "epoch #87, final dev accuracy: 0.28805084745762716\n",
      "train step #82899 accuracy: 0.25, loss: 3.8137478828430176\n",
      "train step #82999 accuracy: 0.265625, loss: 3.907975435256958\n",
      "train step #83099 accuracy: 0.296875, loss: 3.680393934249878\n",
      "train step #83199 accuracy: 0.296875, loss: 3.8637735843658447\n",
      "train step #83299 accuracy: 0.296875, loss: 3.723374843597412\n",
      "train step #83399 accuracy: 0.3671875, loss: 3.467060089111328\n",
      "train step #83499 accuracy: 0.3359375, loss: 3.445333957672119\n",
      "train step #83599 accuracy: 0.3359375, loss: 3.334987163543701\n",
      "train step #83699 accuracy: 0.328125, loss: 3.552233934402466\n",
      "train step #83799 accuracy: 0.265625, loss: 3.826448440551758\n",
      "epoch #88, final dev accuracy: 0.28705508474576275\n",
      "train step #83899 accuracy: 0.2578125, loss: 3.8196773529052734\n",
      "train step #83999 accuracy: 0.3125, loss: 3.6337344646453857\n",
      "train step #84099 accuracy: 0.296875, loss: 3.7975857257843018\n",
      "train step #84199 accuracy: 0.3359375, loss: 3.320030927658081\n",
      "train step #84299 accuracy: 0.28125, loss: 3.6405863761901855\n",
      "train step #84399 accuracy: 0.3828125, loss: 3.503173589706421\n",
      "train step #84499 accuracy: 0.2578125, loss: 3.822016716003418\n",
      "train step #84599 accuracy: 0.296875, loss: 3.8618617057800293\n",
      "train step #84699 accuracy: 0.3203125, loss: 3.564692735671997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #89, final dev accuracy: 0.2913771186440678\n",
      "saving best model...\n",
      "train step #84799 accuracy: 0.3203125, loss: 3.676720142364502\n",
      "train step #84899 accuracy: 0.390625, loss: 3.5005083084106445\n",
      "train step #84999 accuracy: 0.25, loss: 3.7066571712493896\n",
      "train step #85099 accuracy: 0.25, loss: 3.7964060306549072\n",
      "train step #85199 accuracy: 0.2890625, loss: 3.5945591926574707\n",
      "train step #85299 accuracy: 0.28125, loss: 3.5681796073913574\n",
      "train step #85399 accuracy: 0.265625, loss: 3.8676888942718506\n",
      "train step #85499 accuracy: 0.2578125, loss: 3.772907018661499\n",
      "train step #85599 accuracy: 0.328125, loss: 3.433354616165161\n",
      "train step #85699 accuracy: 0.296875, loss: 3.737520694732666\n",
      "epoch #90, final dev accuracy: 0.28979872881355934\n",
      "train step #85799 accuracy: 0.296875, loss: 3.69010329246521\n",
      "train step #85899 accuracy: 0.265625, loss: 3.7847838401794434\n",
      "train step #85999 accuracy: 0.3359375, loss: 3.7734272480010986\n",
      "train step #86099 accuracy: 0.3203125, loss: 3.6585819721221924\n",
      "train step #86199 accuracy: 0.234375, loss: 3.5665152072906494\n",
      "train step #86299 accuracy: 0.2890625, loss: 3.7463111877441406\n",
      "train step #86399 accuracy: 0.375, loss: 3.3258540630340576\n",
      "train step #86499 accuracy: 0.2890625, loss: 3.7839550971984863\n",
      "train step #86599 accuracy: 0.328125, loss: 3.6190712451934814\n",
      "epoch #91, final dev accuracy: 0.28805879237288134\n",
      "train step #86699 accuracy: 0.265625, loss: 3.72247052192688\n",
      "train step #86799 accuracy: 0.2578125, loss: 3.6119260787963867\n",
      "train step #86899 accuracy: 0.3125, loss: 3.628438711166382\n",
      "train step #86999 accuracy: 0.2890625, loss: 3.6828131675720215\n",
      "train step #87099 accuracy: 0.296875, loss: 3.8092761039733887\n",
      "train step #87199 accuracy: 0.3203125, loss: 3.7529189586639404\n",
      "train step #87299 accuracy: 0.3125, loss: 3.668722629547119\n",
      "train step #87399 accuracy: 0.265625, loss: 3.7279446125030518\n",
      "train step #87499 accuracy: 0.359375, loss: 3.47713303565979\n",
      "train step #87599 accuracy: 0.25, loss: 3.739710569381714\n",
      "epoch #92, final dev accuracy: 0.28872881355932206\n",
      "train step #87699 accuracy: 0.3828125, loss: 3.6776010990142822\n",
      "train step #87799 accuracy: 0.3203125, loss: 3.4876179695129395\n",
      "train step #87899 accuracy: 0.2734375, loss: 3.7798562049865723\n",
      "train step #87999 accuracy: 0.328125, loss: 3.6479501724243164\n",
      "train step #88099 accuracy: 0.296875, loss: 3.5324368476867676\n",
      "train step #88199 accuracy: 0.28125, loss: 3.74855375289917\n",
      "train step #88299 accuracy: 0.359375, loss: 3.454465389251709\n",
      "train step #88399 accuracy: 0.375, loss: 3.1801249980926514\n",
      "train step #88499 accuracy: 0.2265625, loss: 4.048415660858154\n",
      "epoch #93, final dev accuracy: 0.2910460805084746\n",
      "train step #88599 accuracy: 0.28125, loss: 3.757054328918457\n",
      "train step #88699 accuracy: 0.2890625, loss: 3.616872787475586\n",
      "train step #88799 accuracy: 0.3359375, loss: 3.6803510189056396\n",
      "train step #88899 accuracy: 0.359375, loss: 3.5984203815460205\n",
      "train step #88999 accuracy: 0.2890625, loss: 3.648113489151001\n",
      "train step #89099 accuracy: 0.2890625, loss: 4.040881156921387\n",
      "train step #89199 accuracy: 0.34375, loss: 3.5864174365997314\n",
      "train step #89299 accuracy: 0.3203125, loss: 3.5246591567993164\n",
      "train step #89399 accuracy: 0.34375, loss: 3.4545164108276367\n",
      "epoch #94, final dev accuracy: 0.2899602754237288\n",
      "train step #89499 accuracy: 0.2578125, loss: 4.018030166625977\n",
      "train step #89599 accuracy: 0.3359375, loss: 3.602674722671509\n",
      "train step #89699 accuracy: 0.2578125, loss: 3.656850576400757\n",
      "train step #89799 accuracy: 0.2734375, loss: 3.618347644805908\n",
      "train step #89899 accuracy: 0.3125, loss: 3.6075165271759033\n",
      "train step #89999 accuracy: 0.265625, loss: 3.6879281997680664\n",
      "train step #90099 accuracy: 0.2265625, loss: 3.918968677520752\n",
      "train step #90199 accuracy: 0.3203125, loss: 3.373718738555908\n",
      "train step #90299 accuracy: 0.3125, loss: 3.7808175086975098\n",
      "train step #90399 accuracy: 0.265625, loss: 3.878962993621826\n",
      "epoch #95, final dev accuracy: 0.2936864406779661\n",
      "saving best model...\n",
      "train step #90499 accuracy: 0.3046875, loss: 3.6591758728027344\n",
      "train step #90599 accuracy: 0.296875, loss: 3.67754864692688\n",
      "train step #90699 accuracy: 0.3203125, loss: 3.5544681549072266\n",
      "train step #90799 accuracy: 0.2578125, loss: 3.6454992294311523\n",
      "train step #90899 accuracy: 0.328125, loss: 3.5841689109802246\n",
      "train step #90999 accuracy: 0.34375, loss: 3.412980318069458\n",
      "train step #91099 accuracy: 0.328125, loss: 3.4311203956604004\n",
      "train step #91199 accuracy: 0.3203125, loss: 3.931363344192505\n",
      "train step #91299 accuracy: 0.359375, loss: 3.51613450050354\n",
      "epoch #96, final dev accuracy: 0.28961069915254234\n",
      "train step #91399 accuracy: 0.2890625, loss: 3.7468628883361816\n",
      "train step #91499 accuracy: 0.328125, loss: 3.580019235610962\n",
      "train step #91599 accuracy: 0.3046875, loss: 3.7638001441955566\n",
      "train step #91699 accuracy: 0.28125, loss: 3.56127667427063\n",
      "train step #91799 accuracy: 0.2421875, loss: 4.1018385887146\n",
      "train step #91899 accuracy: 0.3125, loss: 3.582890748977661\n",
      "train step #91999 accuracy: 0.2109375, loss: 3.9317307472229004\n",
      "train step #92099 accuracy: 0.3359375, loss: 3.5716755390167236\n",
      "train step #92199 accuracy: 0.3828125, loss: 3.2485432624816895\n",
      "train step #92299 accuracy: 0.1953125, loss: 4.180868625640869\n",
      "epoch #97, final dev accuracy: 0.2876324152542373\n",
      "train step #92399 accuracy: 0.3046875, loss: 3.594620704650879\n",
      "train step #92499 accuracy: 0.2734375, loss: 3.9124438762664795\n",
      "train step #92599 accuracy: 0.2734375, loss: 3.5445709228515625\n",
      "train step #92699 accuracy: 0.3046875, loss: 3.501040458679199\n",
      "train step #92799 accuracy: 0.328125, loss: 3.7131521701812744\n",
      "train step #92899 accuracy: 0.3125, loss: 3.663933277130127\n",
      "train step #92999 accuracy: 0.2890625, loss: 3.863386631011963\n",
      "train step #93099 accuracy: 0.3125, loss: 3.7345457077026367\n",
      "train step #93199 accuracy: 0.328125, loss: 3.912092447280884\n",
      "epoch #98, final dev accuracy: 0.29002383474576277\n",
      "train step #93299 accuracy: 0.3125, loss: 3.8319945335388184\n",
      "train step #93399 accuracy: 0.359375, loss: 3.326681137084961\n",
      "train step #93499 accuracy: 0.3046875, loss: 3.7800815105438232\n",
      "train step #93599 accuracy: 0.3359375, loss: 3.541891574859619\n",
      "train step #93699 accuracy: 0.3125, loss: 3.6739208698272705\n",
      "train step #93799 accuracy: 0.3203125, loss: 3.4677200317382812\n",
      "train step #93899 accuracy: 0.2734375, loss: 3.6348037719726562\n",
      "train step #93999 accuracy: 0.25, loss: 3.778796434402466\n",
      "train step #94099 accuracy: 0.265625, loss: 3.8459160327911377\n",
      "train step #94199 accuracy: 0.3203125, loss: 3.9087023735046387\n",
      "epoch #99, final dev accuracy: 0.2884666313559322\n",
      "final test accuracy: 0.2955223880597015\n"
     ]
    }
   ],
   "source": [
    "# si_model.load(\"models/voxc/si_voxc_frames_res8w.pt\")\n",
    "# si_config['n_epochs'] = 0\n",
    "hk.train(si_config, model=si_model, _collate_fn=hk._random_frames_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV Enrollment & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "enroll_spks = sv_spks[:5]\n",
    "test_spks = sv_spks[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olivia_Munn', 'Sam_Palladio', 'Ellen_Wong', 'Karl_Malden', 'Nina_Arianda']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enroll_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Violante_Placido',\n",
       " 'Michael_Weatherly',\n",
       " 'Thomas_Jane',\n",
       " 'Damon_Wayans',\n",
       " 'Shemar_Moore',\n",
       " 'Beth_Grant',\n",
       " 'Shiri_Appleby',\n",
       " 'Claudia_Lee',\n",
       " 'Steven_Soderbergh',\n",
       " 'Marisa_Miller',\n",
       " 'Blake_Michael',\n",
       " 'Jacqueline_MacInnes_Wood',\n",
       " 'Joan_Cusack',\n",
       " 'Walter_Matthau',\n",
       " 'Alex_Pettyfer',\n",
       " 'Julianne_Nicholson',\n",
       " 'Donal_Logue',\n",
       " 'Steve_Harvey',\n",
       " 'Raoul_Bova',\n",
       " 'Audrina_Patridge',\n",
       " 'Ellen_Burstyn',\n",
       " 'Jason_Dohring',\n",
       " 'Max_Thieriot',\n",
       " 'Chris_Lowell',\n",
       " 'Leslie_Bibb',\n",
       " 'Fanny_Ardant',\n",
       " 'Gary_Busey',\n",
       " 'Kim_Zolciak-Biermann',\n",
       " 'Katie_Stevens',\n",
       " 'Dane_Cook',\n",
       " 'Will_Mellor',\n",
       " 'Shannen_Doherty',\n",
       " 'Iain_Glen',\n",
       " 'Jennifer_Coolidge',\n",
       " 'Steve_Burton']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_uttrs = pd.DataFrame()\n",
    "dev_uttrs = pd.DataFrame()\n",
    "enroll_pts = 0.3\n",
    "\n",
    "sv_df = data_df[data_df.spk.isin(sv_spks)]\n",
    "# splits enroll and dev\n",
    "for spk in enroll_spks:\n",
    "    spk_df = sv_df[sv_df.spk == spk]\n",
    "    assert(len(spk_df) != 0)\n",
    "    enls = spk_df.sample(frac=enroll_pts)\n",
    "    devs = spk_df.drop(index=enls.index)\n",
    "    enroll_uttrs = pd.concat([enls, enroll_uttrs])\n",
    "    dev_uttrs = pd.concat([devs, dev_uttrs])\n",
    "    \n",
    "test_uttrs = sv_df[sv_df.spk.isin(test_spks)].sample(n=2*len(dev_uttrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_uttrs.to_pickle(\"./dev_uttrs.pkl\")\n",
    "# test_uttrs.to_pickle(\"./test_uttrs.pkl\")\n",
    "enroll_uttrs = pd.read_pickle(\"./enroll_uttrs.pkl\")\n",
    "dev_uttrs = pd.read_pickle(\"./dev_uttrs.pkl\")\n",
    "test_uttrs = pd.read_pickle(\"./test_uttrs.pkl\")\n",
    "enroll_spks = list(dev_uttrs.spk.unique()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./manifests/voxc/enroll/enroll_voxc_Julianne_Nicholson_manifest.csv was written\n",
      "./manifests/voxc/enroll/enroll_voxc_Alex_Pettyfer_manifest.csv was written\n",
      "./manifests/voxc/enroll/enroll_voxc_Thomas_Jane_manifest.csv was written\n",
      "./manifests/voxc/enroll/enroll_voxc_Chris_Lowell_manifest.csv was written\n",
      "./manifests/voxc/enroll/enroll_voxc_Shiri_Appleby_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "manifest_dir = \"./manifests/voxc/enroll/\"\n",
    "# delete existing files\n",
    "for file in os.listdir(manifest_dir):\n",
    "    file_path = os.path.join(manifest_dir, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.unlink(file_path)\n",
    "        \n",
    "\n",
    "for spk in enroll_spks:\n",
    "    samples = []\n",
    "    save_path = os.path.join(manifest_dir,'enroll_{}_{}_manifest.csv'.format(\"voxc\", spk))\n",
    "    with open(save_path, 'w') as f:\n",
    "        for index, row in enroll_uttrs[enroll_uttrs.spk == spk].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = enroll_spks.index(row.spk)\n",
    "            sample = ','.join([file_path, str(label)])\n",
    "            samples.append(sample)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)\n",
    "        print(\"{} was written\".format(save_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_model = si_config['model_class'](si_config)\n",
    "si_model.load(\"models/voxc/si_voxc_frames_res8w_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrolling speakers\n",
    "# generating speaker models\n",
    "si_config['batch_size'] = 1\n",
    "si_config['input_length'] = int(16000*4)\n",
    "manifest_dir = \"./manifests/voxc/enroll/\"\n",
    "spk_models = dict()\n",
    "for spk in enroll_spks:\n",
    "    manifest_path = os.path.join(manifest_dir, 'enroll_{}_{}_manifest.csv'.format(\"voxc\", spk))\n",
    "    si_config['test_manifest'] =  manifest_path\n",
    "    spk_models[spk] = svs.enroll_frame(si_config, model=si_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nina_Arianda, Jason_Dohring: -0.47\n",
      "Nina_Arianda, Joan_Cusack: 0.39\n",
      "Nina_Arianda, Walter_Matthau: -0.33\n",
      "Nina_Arianda, Max_Thieriot: -0.21\n",
      "Jason_Dohring, Joan_Cusack: -0.54\n",
      "Jason_Dohring, Walter_Matthau: 0.32\n",
      "Jason_Dohring, Max_Thieriot: 0.57\n",
      "Joan_Cusack, Walter_Matthau: -0.56\n",
      "Joan_Cusack, Max_Thieriot: -0.39\n",
      "Walter_Matthau, Max_Thieriot: 0.09\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import itertools\n",
    "\n",
    "for spk1, spk2 in itertools.combinations(enroll_spks,2):\n",
    "    score = 1-cosine(spk_models[spk1], spk_models[spk2])\n",
    "    print(\"{}, {}: {:.2f}\".format(spk1, spk2, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_cosine(spk_model, test_in):\n",
    "    nb_enroll_spks = len(spk_models.keys())\n",
    "    scores = np.zeros(nb_enroll_spks)\n",
    "    for i in range(nb_enroll_spks):\n",
    "        signature = spk_model[i]\n",
    "        scores[i] = 1-cosine(test_in, signature)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_total_uttrs = len(dev_uttrs)+len(test_uttrs)\n",
    "n_classes = len(enroll_spks)\n",
    "score_vector = np.zeros((nb_total_uttrs, n_classes))\n",
    "label_vector = np.zeros((nb_total_uttrs, n_classes))\n",
    "\n",
    "spk_model = [v for k,v in spk_models.items()]\n",
    "spk_labels = list(spk_models.keys())\n",
    "\n",
    "i = 0\n",
    "for idx, row in dev_uttrs.iterrows():\n",
    "    audio_path = os.path.join(data_dir, row.spk, row.file)\n",
    "    emb = svs.dvector(si_config, si_model, audio_path)\n",
    "    score_vector[i, :] = pairwise_cosine(spk_model, emb)\n",
    "    label = spk_labels.index(row.spk)\n",
    "    label_vector[i, label] = 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in test_uttrs.iterrows():\n",
    "    audio_path = os.path.join(data_dir, row.spk, row.file)\n",
    "    emb = svs.dvector(si_config, si_model, audio_path)\n",
    "    score_vector[i, :] = pairwise_cosine(spk_model, emb)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAG5CAYAAADVp6NgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWJUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7216271ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "eer = dict()\n",
    "thres = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], thres[i] = roc_curve(label_vector[:, i], score_vector[:, i], pos_label=1)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], thres[\"micro\"] = roc_curve(label_vector.ravel(), score_vector.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "eer[\"micro\"] = fpr[\"micro\"][np.nanargmin(np.abs(fpr[\"micro\"] - (1 - tpr[\"micro\"])))]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    eer[i] = fpr[i][np.nanargmin(np.abs(fpr[i] - (1 - tpr[i])))]\n",
    "\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "lw = 2\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "eer[\"macro\"] = fpr[\"macro\"][np.nanargmin(np.abs(fpr[\"macro\"] - (1 - tpr[\"macro\"])))]\n",
    "# Plot all ROC curves\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f}, eer = {1:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"], eer[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f}, eer = {1:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"], eer[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of {0} (area = {1:0.2f}, eer = {2:0.4f})'\n",
    "             ''.format(spk_labels[i], roc_auc[i], eer[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class (voxc_frames)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

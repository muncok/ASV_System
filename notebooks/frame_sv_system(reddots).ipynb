{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['mod', 'sample', 'f', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/muncok/DL/projects/sv_system/\")\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "from honk_sv import train as train\n",
    "from honk_sv import model as mod\n",
    "from honk_sv import dataset as dset\n",
    "from honk_sv import system as svs\n",
    "from honk_sv import dataloader as dloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "command: disjoint speaker split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dir = '/home/muncok/DL/dataset/SV_sets/dataframes/'\n",
    "data_dir = '/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/'\n",
    "data_df = pd.read_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Reddots_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import honk_sv.train as hk\n",
    "from honk_sv import model as mod\n",
    "from honk_sv import dataset as dset\n",
    "from honk_sv import system as svs\n",
    "from honk_sv import dataloader as dloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spks = data_df.spk.unique()\n",
    "all_sents = data_df.sent.unique()\n",
    "uttrs_counts = data_df.spk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_spks = list(uttrs_counts[uttrs_counts > 100].index)\n",
    "sv_spks = list(uttrs_counts[uttrs_counts <= 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[random] train:11747, val:2937, test:2937\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "si_df = data_df[data_df.spk.isin(si_spks)]\n",
    "\n",
    "# random sampling\n",
    "si_random_train = si_df.sample(frac=0.8)\n",
    "si_random_test = si_df.drop(index=si_random_train.index)\n",
    "si_random_val = si_random_test\n",
    "print(\"[random] train:{}, val:{}, test:{}\".format(len(si_random_train), len(si_random_val), len(si_random_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../manifests/reddots/si_reddots_train_manifest.csv was written\n",
      "../manifests/reddots/si_reddots_val_manifest.csv was written\n",
      "../manifests/reddots/si_reddots_test_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "tags = ['train', 'val', 'test']\n",
    "# choose a si split\n",
    "sets = {'train':si_random_train, 'val':si_random_val, 'test':si_random_test}\n",
    "manifest_dir = \"../manifests/reddots/\"\n",
    "\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    save_path = os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"reddots\", tag))\n",
    "    with open(save_path, 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = si_spks.index(row.spk)\n",
    "            sample = ','.join([file_path, str(label)])\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)\n",
    "        print(\"{} was written\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../manifests/reddots/sv_reddots_manifest.csv was written\n"
     ]
    }
   ],
   "source": [
    "# sv write_manifest\n",
    "samples = []\n",
    "save_path = os.path.join(manifest_dir,'sv_{}_manifest.csv'.format(\"reddots\"))\n",
    "sv_df = data_df[data_df.spk.isin(sv_spks)]\n",
    "with open(save_path, 'w') as f:\n",
    "    for index, row in sv_df.iterrows():\n",
    "        file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "        label = sv_spks.index(row.spk)\n",
    "        sample = ','.join([file_path, str(label)])\n",
    "        samples.append(sample)\n",
    "    writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "    writer.writerow(samples)\n",
    "    print(\"{} was written\".format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SimpleCNN\"\n",
    "dataset = \"reddots\"\n",
    "\n",
    "global_config = dict(model=model, dataset=dataset,\n",
    "                     no_cuda=False,  gpu_no=0,\n",
    "                     n_epochs=100, batch_size=64,\n",
    "                     lr=[0.01], schedule=[np.inf], dev_every=1, seed=0, use_nesterov=False,\n",
    "                     cache_size=32768, momentum=0.9, weight_decay=0.00001,\n",
    "                     num_workers=16, print_step=100,\n",
    "                     splice_length=20\n",
    "                     )\n",
    "\n",
    "builder = train.ConfigBuilder(\n",
    "                dset.SpeechDataset.default_config(dataset),\n",
    "                global_config)\n",
    "parser = builder.build_argparse()\n",
    "si_config = builder.config_from_argparse(parser)\n",
    "si_config['model_class'] = mod.SimpleCNN\n",
    "train.set_seed(si_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_config['n_labels'] = len(si_spks)\n",
    "si_config['input_length'] = int(16000*0.2)\n",
    "manifest_dir = \"../manifests/reddots/\"\n",
    "for tag in ['train', 'val', 'test']:\n",
    "    si_config['{}_manifest'.format(tag)]=os.path.join(manifest_dir,'si_{}_{}_manifest.csv'.format(\"reddots\", tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "si_model = si_config['model_class']()\n",
    "time_dim = si_config['input_length']//160+1\n",
    "test_in = Variable(torch.zeros(1,1,time_dim,40), volatile=True)\n",
    "test_out = si_model(test_in)\n",
    "si_model.feat_size = test_out.size(1)\n",
    "si_model.output = nn.Linear(test_out.size(1), si_config[\"n_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #99 accuracy: 0.171875, loss: 3.1852052211761475\n",
      "epoch #0, final dev accuracy: 0.3180897215865751\n",
      "saving best model...\n",
      "train step #199 accuracy: 0.359375, loss: 2.4508121013641357\n",
      "train step #299 accuracy: 0.390625, loss: 1.8864681720733643\n",
      "epoch #1, final dev accuracy: 0.4989631006864989\n",
      "saving best model...\n",
      "train step #399 accuracy: 0.4375, loss: 1.7626347541809082\n",
      "train step #499 accuracy: 0.453125, loss: 1.7073249816894531\n",
      "epoch #2, final dev accuracy: 0.6330389492753623\n",
      "saving best model...\n",
      "train step #599 accuracy: 0.5, loss: 1.2475086450576782\n",
      "train step #699 accuracy: 0.578125, loss: 1.156954288482666\n",
      "epoch #3, final dev accuracy: 0.5985650266971777\n",
      "train step #799 accuracy: 0.6875, loss: 1.3311842679977417\n",
      "train step #899 accuracy: 0.765625, loss: 0.9914790391921997\n",
      "epoch #4, final dev accuracy: 0.6462028032036613\n",
      "saving best model...\n",
      "train step #999 accuracy: 0.640625, loss: 1.0650572776794434\n",
      "epoch #5, final dev accuracy: 0.7610483409610984\n",
      "saving best model...\n",
      "train step #1099 accuracy: 0.734375, loss: 0.9568945169448853\n",
      "train step #1199 accuracy: 0.75, loss: 1.0133488178253174\n",
      "epoch #6, final dev accuracy: 0.7087862318840579\n",
      "train step #1299 accuracy: 0.765625, loss: 0.7675607800483704\n",
      "train step #1399 accuracy: 0.703125, loss: 1.0129481554031372\n",
      "epoch #7, final dev accuracy: 0.7428787662090007\n",
      "train step #1499 accuracy: 0.671875, loss: 1.0686371326446533\n",
      "train step #1599 accuracy: 0.734375, loss: 0.7211175560951233\n",
      "epoch #8, final dev accuracy: 0.7852069031273837\n",
      "saving best model...\n",
      "train step #1699 accuracy: 0.78125, loss: 0.7381229400634766\n",
      "train step #1799 accuracy: 0.6875, loss: 1.0212137699127197\n",
      "epoch #9, final dev accuracy: 0.7704757818459191\n",
      "train step #1899 accuracy: 0.84375, loss: 0.6571502089500427\n",
      "train step #1999 accuracy: 0.8125, loss: 0.5453387498855591\n",
      "epoch #10, final dev accuracy: 0.775779462242563\n",
      "train step #2099 accuracy: 0.765625, loss: 0.6861913800239563\n",
      "epoch #11, final dev accuracy: 0.8267305491990847\n",
      "saving best model...\n",
      "train step #2199 accuracy: 0.859375, loss: 0.4776492714881897\n",
      "train step #2299 accuracy: 0.828125, loss: 0.6425268054008484\n",
      "epoch #12, final dev accuracy: 0.8045266018306636\n",
      "train step #2399 accuracy: 0.796875, loss: 0.7845031023025513\n",
      "train step #2499 accuracy: 0.828125, loss: 0.6061410903930664\n",
      "epoch #13, final dev accuracy: 0.7827457570556827\n",
      "train step #2599 accuracy: 0.75, loss: 0.5923272967338562\n",
      "train step #2699 accuracy: 0.859375, loss: 0.5881652235984802\n",
      "epoch #14, final dev accuracy: 0.8348827231121282\n",
      "saving best model...\n",
      "train step #2799 accuracy: 0.71875, loss: 0.7261184453964233\n",
      "train step #2899 accuracy: 0.796875, loss: 0.6506165266036987\n",
      "epoch #15, final dev accuracy: 0.8227438501144164\n",
      "train step #2999 accuracy: 0.703125, loss: 0.7533474564552307\n",
      "train step #3099 accuracy: 0.78125, loss: 0.6222517490386963\n",
      "epoch #16, final dev accuracy: 0.8257115274599542\n",
      "train step #3199 accuracy: 0.828125, loss: 0.57218337059021\n",
      "epoch #17, final dev accuracy: 0.8195556826849734\n",
      "train step #3299 accuracy: 0.859375, loss: 0.42730045318603516\n",
      "train step #3399 accuracy: 0.796875, loss: 0.48682504892349243\n",
      "epoch #18, final dev accuracy: 0.7548090675057209\n",
      "train step #3499 accuracy: 0.796875, loss: 0.6302998065948486\n",
      "train step #3599 accuracy: 0.8125, loss: 0.40847864747047424\n",
      "epoch #19, final dev accuracy: 0.813227021357742\n",
      "train step #3699 accuracy: 0.84375, loss: 0.49127811193466187\n",
      "train step #3799 accuracy: 0.796875, loss: 0.5490564107894897\n",
      "epoch #20, final dev accuracy: 0.835138968344775\n",
      "saving best model...\n",
      "train step #3899 accuracy: 0.875, loss: 0.40645191073417664\n",
      "train step #3999 accuracy: 0.75, loss: 0.7825393676757812\n",
      "epoch #21, final dev accuracy: 0.7766316266209001\n",
      "train step #4099 accuracy: 0.828125, loss: 0.6144225597381592\n",
      "train step #4199 accuracy: 0.875, loss: 0.3610871136188507\n",
      "epoch #22, final dev accuracy: 0.8511453565980168\n",
      "saving best model...\n",
      "train step #4299 accuracy: 0.828125, loss: 0.45489567518234253\n",
      "epoch #23, final dev accuracy: 0.8744100400457665\n",
      "saving best model...\n",
      "train step #4399 accuracy: 0.8125, loss: 0.8687905669212341\n",
      "train step #4499 accuracy: 0.875, loss: 0.4933503568172455\n",
      "epoch #24, final dev accuracy: 0.8623545957284516\n",
      "train step #4599 accuracy: 0.859375, loss: 0.4087836444377899\n",
      "train step #4699 accuracy: 0.84375, loss: 0.6237963438034058\n",
      "epoch #25, final dev accuracy: 0.8677893783371473\n",
      "train step #4799 accuracy: 0.875, loss: 0.398034930229187\n",
      "train step #4899 accuracy: 0.796875, loss: 0.7157361507415771\n",
      "epoch #26, final dev accuracy: 0.8410802822273074\n",
      "train step #4999 accuracy: 0.84375, loss: 0.4327687621116638\n",
      "train step #5099 accuracy: 0.703125, loss: 0.9185349345207214\n",
      "epoch #27, final dev accuracy: 0.8655785183066361\n",
      "train step #5199 accuracy: 0.890625, loss: 0.4330454468727112\n",
      "train step #5299 accuracy: 0.78125, loss: 0.5743986368179321\n",
      "epoch #28, final dev accuracy: 0.8416344870327994\n",
      "train step #5399 accuracy: 0.890625, loss: 0.34864166378974915\n",
      "epoch #29, final dev accuracy: 0.8565801392067125\n",
      "train step #5499 accuracy: 0.859375, loss: 0.37824761867523193\n",
      "train step #5599 accuracy: 0.859375, loss: 0.4970872104167938\n",
      "epoch #30, final dev accuracy: 0.8705484839816934\n",
      "train step #5699 accuracy: 0.890625, loss: 0.3841937184333801\n",
      "train step #5799 accuracy: 0.890625, loss: 0.24629200994968414\n",
      "epoch #31, final dev accuracy: 0.8318673722349352\n",
      "train step #5899 accuracy: 0.9375, loss: 0.174017995595932\n",
      "train step #5999 accuracy: 0.90625, loss: 0.30751192569732666\n",
      "epoch #32, final dev accuracy: 0.8437619183829138\n",
      "train step #6099 accuracy: 0.84375, loss: 0.4530303478240967\n",
      "train step #6199 accuracy: 0.875, loss: 0.39614591002464294\n",
      "epoch #33, final dev accuracy: 0.8785278413424866\n",
      "saving best model...\n",
      "train step #6299 accuracy: 0.828125, loss: 0.4388432502746582\n",
      "train step #6399 accuracy: 0.828125, loss: 0.4421635866165161\n",
      "epoch #34, final dev accuracy: 0.840615465293669\n",
      "train step #6499 accuracy: 0.859375, loss: 0.3927394151687622\n",
      "epoch #35, final dev accuracy: 0.8526291952707856\n",
      "train step #6599 accuracy: 0.9375, loss: 0.21360188722610474\n",
      "train step #6699 accuracy: 0.890625, loss: 0.4074239730834961\n",
      "epoch #36, final dev accuracy: 0.8689335430968725\n",
      "train step #6799 accuracy: 0.875, loss: 0.42888686060905457\n",
      "train step #6899 accuracy: 0.890625, loss: 0.3871806561946869\n",
      "epoch #37, final dev accuracy: 0.8762812261632342\n",
      "train step #6999 accuracy: 0.828125, loss: 0.4208473265171051\n",
      "train step #7099 accuracy: 0.859375, loss: 0.36535412073135376\n",
      "epoch #38, final dev accuracy: 0.8767877574370708\n",
      "train step #7199 accuracy: 0.9375, loss: 0.2953892946243286\n",
      "train step #7299 accuracy: 0.890625, loss: 0.34177231788635254\n",
      "epoch #39, final dev accuracy: 0.8712695461479787\n",
      "train step #7399 accuracy: 0.890625, loss: 0.2916790544986725\n",
      "train step #7499 accuracy: 0.9375, loss: 0.30151861906051636\n",
      "epoch #40, final dev accuracy: 0.8558590770404272\n",
      "train step #7599 accuracy: 0.921875, loss: 0.1720270961523056\n",
      "epoch #41, final dev accuracy: 0.855561117467582\n",
      "train step #7699 accuracy: 0.921875, loss: 0.2289992868900299\n",
      "train step #7799 accuracy: 0.9375, loss: 0.20676937699317932\n",
      "epoch #42, final dev accuracy: 0.867193459191457\n",
      "train step #7899 accuracy: 0.890625, loss: 0.3830506205558777\n",
      "train step #7999 accuracy: 0.90625, loss: 0.2320348471403122\n",
      "epoch #43, final dev accuracy: 0.8676582761250953\n",
      "train step #8099 accuracy: 0.890625, loss: 0.3572692573070526\n",
      "train step #8199 accuracy: 0.828125, loss: 0.35310596227645874\n",
      "epoch #44, final dev accuracy: 0.8804407418001526\n",
      "saving best model...\n",
      "train step #8299 accuracy: 0.875, loss: 0.34434956312179565\n",
      "train step #8399 accuracy: 0.890625, loss: 0.32888171076774597\n",
      "epoch #45, final dev accuracy: 0.8383211765827613\n",
      "train step #8499 accuracy: 0.84375, loss: 0.39020484685897827\n",
      "train step #8599 accuracy: 0.890625, loss: 0.35345643758773804\n",
      "epoch #46, final dev accuracy: 0.8736055491990847\n",
      "train step #8699 accuracy: 0.9375, loss: 0.28251343965530396\n",
      "epoch #47, final dev accuracy: 0.8679562356979404\n",
      "train step #8799 accuracy: 0.859375, loss: 0.3823453485965729\n",
      "train step #8899 accuracy: 0.890625, loss: 0.2355232536792755\n",
      "epoch #48, final dev accuracy: 0.889272263539283\n",
      "saving best model...\n",
      "train step #8999 accuracy: 0.828125, loss: 0.46659159660339355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step #9099 accuracy: 0.90625, loss: 0.21386298537254333\n",
      "epoch #49, final dev accuracy: 0.8854107074752098\n",
      "train step #9199 accuracy: 0.875, loss: 0.44619831442832947\n",
      "train step #9299 accuracy: 0.875, loss: 0.2925673723220825\n",
      "epoch #50, final dev accuracy: 0.839810974446987\n",
      "train step #9399 accuracy: 0.9375, loss: 0.1790803223848343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4855:\n",
      "KeyboardInterrupt\n",
      "Process Process-4853:\n",
      "Process Process-4861:\n",
      "Process Process-4856:\n",
      "Process Process-4854:\n",
      "Process Process-4858:\n",
      "Process Process-4860:\n",
      "Process Process-4864:\n",
      "Process Process-4849:\n",
      "Process Process-4862:\n",
      "Process Process-4857:\n",
      "Process Process-4850:\n",
      "Process Process-4851:\n",
      "Process Process-4859:\n",
      "Process Process-4863:\n",
      "Process Process-4852:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 45900) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2909\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2910\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2911\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-8a5fc7d75a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msi_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../models/reddots/si_reddots_0.2s.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msi_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DL/projects/sv_system/honk_sv/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, loaders, model, _collate_fn)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1827\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1831\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1371\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1279\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m             )\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1128\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mformatted_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_records\u001b[0;34m(self, records, last_unique, recursion_repeat)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast_unique\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_record\u001b[0;34m(self, frame, file, lnum, func, lines, index)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             return '%s%s' % (level, ''.join(\n\u001b[1;32m   1001\u001b[0m                 _format_traceback_lines(lnum, index, lines, Colors, lvals,\n\u001b[0;32m-> 1002\u001b[0;31m                                          _line_format)))\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36m_format_traceback_lines\u001b[0;34m(lnum, index, lines, Colors, lvals, _line_format)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy3compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mnew_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_line_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/utils/PyColorize.py\u001b[0m in \u001b[0;36mformat2\u001b[0;34m(self, raw, out)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0matoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0matoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0mpseudomatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPseudoToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpseudomatch\u001b[0m\u001b[0;34m:\u001b[0m                                \u001b[0;31m# scan for tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpseudomatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 45900) exited unexpectedly with exit code 1."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 111, in preprocess\n",
      "    self._file_cache[example] = data\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 25, in __setitem__\n",
      "    super().__setitem__(key, value)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 110, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 110, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 110, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 121, in load\n",
      "    for frame in input_file:\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1388, in melspectrogram\n",
      "    power=power)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 110, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 122, in load\n",
      "    frame = util.buf_to_float(frame, dtype=dtype)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 122, in load\n",
      "    frame = util.buf_to_float(frame, dtype=dtype)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/audioread/rawread.py\", line 130, in read_data\n",
      "    data = self._file.readframes(block_samples)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 1179, in _spectrogram\n",
      "    S = np.abs(stft(y, n_fft=n_fft, hop_length=hop_length))**power\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 251, in mel\n",
      "    weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 314, in __getitem__\n",
      "    return self.preprocess(self.audio_files[index]), self.audio_labels[index]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 155, in load\n",
      "    y = resample(y, sr_native, sr, res_type=res_type)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 110, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 25, in preprocess_audio\n",
      "    data = [np.matmul(dct_filters, x) for x in np.split(data, data.shape[1], axis=1)]\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 1359, in buf_to_float\n",
      "    return scale * np.frombuffer(x, fmt).astype(dtype)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 251, in mel\n",
      "    weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/wave.py\", line 242, in readframes\n",
      "    data = self._data_chunk.read(nframes * self._framesize)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 1356, in buf_to_float\n",
      "    fmt = '<i{:d}'.format(n_bytes)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/dataset.py\", line 129, in preprocess\n",
      "    audio_data = preprocess_audio(data, self.n_mels, self.filters)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 269, in resample\n",
      "    util.valid_audio(y, mono=False)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/lib/shape_base.py\", line 560, in split\n",
      "    res = array_split(ary, indices_or_sections, axis)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/audio.py\", line 122, in load\n",
      "    frame = util.buf_to_float(frame, dtype=dtype)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/chunk.py\", line 136, in read\n",
      "    data = self.file.read(size)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/DL/projects/sv_system/honk_sv/manage_audio.py\", line 23, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 251, in mel\n",
      "    weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 156, in valid_audio\n",
      "    if not np.isfinite(y).all():\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/lib/shape_base.py\", line 479, in array_split\n",
      "    st = div_points[i]\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1388, in melspectrogram\n",
      "    power=power)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/util/utils.py\", line 1359, in buf_to_float\n",
      "    return scale * np.frombuffer(x, fmt).astype(dtype)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 251, in mel\n",
      "    weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/chunk.py\", line 136, in read\n",
      "    data = self.file.read(size)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 240, in mel\n",
      "    mel_f = mel_frequencies(n_mels + 2, fmin=fmin, fmax=fmax, htk=htk)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1391, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/core/_methods.py\", line 41, in _all\n",
      "    return umr_all(a, axis, dtype, out, keepdims)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 1179, in _spectrogram\n",
      "    S = np.abs(stft(y, n_fft=n_fft, hop_length=hop_length))**power\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 240, in mel\n",
      "    mel_f = mel_frequencies(n_mels + 2, fmin=fmin, fmax=fmax, htk=htk)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/filters.py\", line 251, in mel\n",
      "    weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/time_frequency.py\", line 858, in mel_frequencies\n",
      "    min_mel = hz_to_mel(fmin, htk=htk)\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 180, in stft\n",
      "    axis=0)[:stft_matrix.shape[0]].conj()\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/time_frequency.py\", line 863, in mel_frequencies\n",
      "    return mel_to_hz(mels, htk=htk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/time_frequency.py\", line 634, in hz_to_mel\n",
      "    mels[log_t] = min_log_mel + np.log(frequencies[log_t]/min_log_hz) / logstep\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/librosa/core/time_frequency.py\", line 675, in mel_to_hz\n",
      "    freqs = f_min + f_sp * mels\n",
      "  File \"/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/scipy/fftpack/basic.py\", line 285, in fft\n",
      "    tmp = work_function(tmp,n,1,0,overwrite_x)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# si_model.load(\"models/reddots/si_reddots_frames_res8.pt\")\n",
    "si_config['n_epochs'] = 100\n",
    "si_config['output_file'] = \"../models/reddots/si_reddots_0.2s.pt\"\n",
    "hk.train(si_config, model=si_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../manifests/reddots/si_reddots_train_manifest.csv'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_config['train_manifest']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %pylab inline\n",
    "import pandas\n",
    "import os\n",
    "os.sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(spk-sent ID) (utterance01,utterance02,utterance03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RedDots Dataset\n",
    "\n",
    "The RedDots project was initiated, with collaboration from multiple sites, as a follow-up to a special session during INTERSPEECH 2014. It was set out to collect speech data through mobile crowd-sourcing, with the benefit of potentially wider population and greater diversity. The project was rolled out in January 29, 2015.The current RedDots_r2015q4_v1 release contains all the audited recordings up to August 17th 2015. It has 62 speakers including 49 male speakers and 13 female speakers from 21 countries. The total number of sessions for the current release is 572 (473 male and 99 female sessions).\n",
    "\n",
    "__File format__\n",
    "\n",
    "* Enrol (.trn)\n",
    "    * (spk-sent ID) (utterance01,utterance02,utterance03)\n",
    "    * e.g.: m0001_31 m0001/20150130084154554_m0001_31,m0001/20150130084155412_m0001_31,m0001/20150130084156114_m0001_31\n",
    "\n",
    "* Trial (.ndx):\n",
    "    * (spk-sent ID),(test utterance),(is target-correct),(is target-wrong),(is imposter-correct),(is imposter-wrong),\n",
    "    * e.g.: m0001_31,m0001/20150129213253016_m0001_36,N,Y,N,N\n",
    "    \n",
    "    \n",
    "<hr>    \n",
    "\n",
    "|                     |  Male |  Female |  Remark        |\n",
    "|---------------------|-------|---------|----------------|\n",
    "|  # target speakers  |  35   |  6      |  >= 6 sessions |\n",
    "|  # unseen imposters |  14   |  7      |  < 6 sessions  |\n",
    "|  total              |  49   |  13     |  -             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_home_dir = '/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/'\n",
    "rDots_pcm_dir = os.path.join(rDots_home_dir, 'pcm/')\n",
    "rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "rDots_infos_dir = os.path.join(rDots_home_dir, 'infos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do it only once\n",
    "\n",
    "# from glob import glob\n",
    "# import wave\n",
    "\n",
    "# # pcm to wav and save to rDots_wav_dir\n",
    "\n",
    "# def pcm_to_wav(audio_path, target_path, sampling_rate=16000):\n",
    "#     if audio_path.split('.')[-1] != 'pcm':\n",
    "#         raise BaseException('File is not pcm formatted')\n",
    "    \n",
    "#     with open(audio_path, 'rb') as pcmfile:\n",
    "#         pcmdata = pcmfile.read()\n",
    "#     with wave.open(audio_path.replace('pcm', 'wav'), 'wb') as wavfile:\n",
    "#         wavfile.setparams((1, 2, sampling_rate, 0, 'NONE', 'NONE'))\n",
    "#         wavfile.writeframes(pcmdata)\n",
    "\n",
    "        \n",
    "# pcmfiles = []\n",
    "# pattern = '*.pcm'\n",
    "\n",
    "# rDots_pcm_dir = os.path.join(rDots_home_dir, 'pcm/')\n",
    "\n",
    "# rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "\n",
    "# '''\n",
    "# Copy substructure of pcm directory to new wav directory for the first run\n",
    "# '''\n",
    "# if not os.path.exists(rDots_wav_dir):\n",
    "#     os.mkdir(rDots_wav_dir)\n",
    "\n",
    "#     for dirpath, dirnames, filenames in os.walk(rDots_pcm_dir):\n",
    "#         structure = os.path.join(rDots_wav_dir, dirpath[len(rDots_pcm_dir):])\n",
    "#         if not os.path.isdir(structure):\n",
    "#             os.mkdir(structure)\n",
    "\n",
    "# for dir,_,_ in os.walk(os.path.join(rDots_home_dir, 'pcm/')):\n",
    "#     pcmfiles.extend(glob(os.path.join(dir, pattern)))\n",
    "\n",
    "# for pcmfile in pcmfiles:\n",
    "#     pcm_to_wav(pcmfile, os.path.join(rDots_home_dir, 'wav/'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "data_dir = rDots_wav_dir\n",
    "wav_files = {}\n",
    "all_spks = []\n",
    "for _, dirnames, _ in os.walk(data_dir):\n",
    "    for dirname in dirnames:\n",
    "        if os.path.isfile(os.path.abspath(dirname)): continue\n",
    "        spk = dirname\n",
    "        all_spks.append(spk)\n",
    "        for filename in os.listdir(os.path.join(data_dir,dirname)):\n",
    "            time, spk, sent = filename.rstrip('.wav').split('_')\n",
    "            uniqID = filename.rstrip('.wav')\n",
    "            wav_files[uniqID] = (spk, int(sent), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_dict(wav_files, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set df's column names\n",
    "df.columns = ['spk', 'sent', 'file']\n",
    "df['set'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of speakers: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"number of speakers: {}\".format(len(all_spks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = [all_spks.index(x) for x in df.spk]\n",
    "df = df.assign(label = new_col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spk</th>\n",
       "      <th>sent</th>\n",
       "      <th>file</th>\n",
       "      <th>set</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20150401220415579_m0045_40</th>\n",
       "      <td>m0045</td>\n",
       "      <td>40</td>\n",
       "      <td>20150401220415579_m0045_40.wav</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150401220405767_m0045_32</th>\n",
       "      <td>m0045</td>\n",
       "      <td>32</td>\n",
       "      <td>20150401220405767_m0045_32.wav</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150401220349980_m0045_36</th>\n",
       "      <td>m0045</td>\n",
       "      <td>36</td>\n",
       "      <td>20150401220349980_m0045_36.wav</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150401220418653_m0045_17449</th>\n",
       "      <td>m0045</td>\n",
       "      <td>17449</td>\n",
       "      <td>20150401220418653_m0045_17449.wav</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20150401220403099_m0045_566</th>\n",
       "      <td>m0045</td>\n",
       "      <td>566</td>\n",
       "      <td>20150401220403099_m0045_566.wav</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 spk   sent  \\\n",
       "20150401220415579_m0045_40     m0045     40   \n",
       "20150401220405767_m0045_32     m0045     32   \n",
       "20150401220349980_m0045_36     m0045     36   \n",
       "20150401220418653_m0045_17449  m0045  17449   \n",
       "20150401220403099_m0045_566    m0045    566   \n",
       "\n",
       "                                                            file set  label  \n",
       "20150401220415579_m0045_40        20150401220415579_m0045_40.wav          0  \n",
       "20150401220405767_m0045_32        20150401220405767_m0045_32.wav          0  \n",
       "20150401220349980_m0045_36        20150401220349980_m0045_36.wav          0  \n",
       "20150401220418653_m0045_17449  20150401220418653_m0045_17449.wav          0  \n",
       "20150401220403099_m0045_566      20150401220403099_m0045_566.wav          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict speakers\n",
    "chosen_spks = df.spk.value_counts().index[:100].tolist()\n",
    "\n",
    "sv_test = df[(df.set == 'test') & (df.spk.isin(chosen_spks))]\n",
    "sv_val = df[(df.set == 'val') & (df.spk.isin(chosen_spks))]\n",
    "sv_train = df[(df.set == 'train') & (df.spk.isin(chosen_spks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(google_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok google sentence\n",
    "ok_speechs = df[df.sent == 32]\n",
    "google_spk = list(ok_speechs.spk.value_counts().index[np.where(ok_speechs.spk.value_counts() > 10)])\n",
    "# target_ok_speechs = ok_speechs[ok_speechs.spk.isin(google_spk)]\n",
    "\n",
    "train_spk = google_spk[:20]\n",
    "val_spk = google_spk[20:23]\n",
    "test_spk = google_spk[23:]\n",
    "\n",
    "sv_train = ok_speechs[ok_speechs.spk.isin(train_spk)]\n",
    "sv_val = ok_speechs[ok_speechs.spk.isin(val_spk)]\n",
    "sv_test = ok_speechs[ok_speechs.spk.isin(test_spk)]\n",
    "\n",
    "import csv\n",
    "import random\n",
    "tags = ['train', 'val', 'test']\n",
    "sets = {'train':sv_train, 'val':sv_val, 'test':sv_test}\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    with open('sv_reddot_okgoogle_{}_manifest.csv'.format(tag), 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = google_spk.index(row.spk)          \n",
    "            sample = ','.join([file_path, str(label+2)]) # 0,1 for speacial purpose\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_speechs = df[(df.spk.isin(google_spk)) & ~(df.sent == 32)]\n",
    "\n",
    "sv_train = pretrain_speechs.sample(frac=0.8,random_state=200)\n",
    "sv_val = pretrain_speechs.drop(sv_train.index)\n",
    "sv_test = sv_val.sample(frac=0.5)\n",
    "sv_val = sv_val.drop(sv_test.index)\n",
    "\n",
    "import csv\n",
    "import random\n",
    "tags = ['train', 'val', 'test']\n",
    "sets = {'train':sv_train, 'val':sv_val, 'test':sv_test}\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    with open('sv_reddot_pregoogle_{}_manifest.csv'.format(tag), 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = google_spk.index(row.spk)          \n",
    "            sample = ','.join([file_path, str(label+2)]) # 0,1 for speacial purpose\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs for fine-tuning\n",
    "def dfToPath(df):\n",
    "    paths = []\n",
    "    for _,row in df.iterrows():\n",
    "        paths.append(os.path.join(row.spk, row.file))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "val_speakers = test_spk\n",
    "sub_df = sv_test\n",
    "spk_pairs = itertools.combinations_with_replacement(val_speakers,2)\n",
    "neg_audio_pair = []\n",
    "pos_audio_pair = []\n",
    "for spk_a, spk_b in spk_pairs:\n",
    "    if spk_a != spk_b:\n",
    "        audio_a = dfToPath(sub_df[sub_df.spk == spk_a].sample(n=5, replace=False))\n",
    "        audio_b = dfToPath(sub_df[sub_df.spk == spk_b].sample(n=5, replace=False))\n",
    "        neg_audio_pair = itertools.chain(neg_audio_pair, itertools.product(audio_a, audio_b))\n",
    "    else:\n",
    "        audio_a = dfToPath(sub_df[sub_df.spk == spk_a].sample(n=10, replace=False))\n",
    "        pos_audio_pair = itertools.chain(pos_audio_pair, itertools.combinations(audio_a, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "data_dir = \"../../../sv_system/data\"\n",
    "root = rDots_wav_dir\n",
    "with open(os.path.join(data_dir,'sv_reddot_pospair_manifest.csv'), 'w') as f:\n",
    "    for (a, b) in pos_audio_pair:\n",
    "        a_path = os.path.join(root,a)\n",
    "        b_path = os.path.join(root,b)\n",
    "        sample = ','.join([a_path,b_path,str(1)])\n",
    "        samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "    writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "    writer.writerow(samples)\n",
    "\n",
    "samples = []\n",
    "with open(os.path.join(data_dir,'sv_reddot_negpair_manifest.csv'), 'w') as f:\n",
    "    for (a, b) in neg_audio_pair:\n",
    "        a_path = os.path.join(root,a)\n",
    "        b_path = os.path.join(root,b)\n",
    "        sample = ','.join([a_path,b_path,str(0)])\n",
    "        samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "    writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "    writer.writerow(samples)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f43a5c602f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/muncok/DL/dataset/SV_sets/Reddots_Dataframes.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"/home/muncok/DL/dataset/SV_sets/Reddots_Dataframes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

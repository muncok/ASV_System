{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../')\n",
    "import data.data_loader as DL\n",
    "import sys\n",
    "import wave\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_home_dir = '/home/muncok/DL/dataset/reddots_r2015q4_v1/'\n",
    "rDots_pcm_dir = os.path.join(rDots_home_dir, 'pcm/')\n",
    "rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "rDots_infos_dir = os.path.join(rDots_home_dir, 'infos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcm_to_wav(audio_path, target_path, sampling_rate=16000):\n",
    "    if audio_path.split('.')[-1] != 'pcm':\n",
    "        raise BaseException('File is not pcm formatted')\n",
    "    \n",
    "    with open(audio_path, 'rb') as pcmfile:\n",
    "        pcmdata = pcmfile.read()\n",
    "    with wave.open(audio_path.replace('pcm', 'wav'), 'wb') as wavfile:\n",
    "        wavfile.setparams((1, 2, sampling_rate, 0, 'NONE', 'NONE'))\n",
    "        wavfile.writeframes(pcmdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_prepare_files(rDots_home_dir):\n",
    "    pcmfiles = []\n",
    "    pattern = '*.pcm'\n",
    "    \n",
    "    rDots_pcm_dir = os.path.join(rDots_home_dir, 'pcm/')\n",
    "    \n",
    "    rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "    \n",
    "    '''\n",
    "    Copy substructure of pcm directory to new wav directory for the first run\n",
    "    '''\n",
    "    if not os.path.exists(rDots_wav_dir):\n",
    "        os.mkdir(rDots_wav_dir)\n",
    "        \n",
    "        for dirpath, dirnames, filenames in os.walk(rDots_pcm_dir):\n",
    "            structure = os.path.join(rDots_wav_dir, dirpath[len(rDots_pcm_dir):])\n",
    "            if not os.path.isdir(structure):\n",
    "                os.mkdir(structure)\n",
    "    \n",
    "    for dir,_,_ in os.walk(os.path.join(rDots_home_dir, 'pcm/')):\n",
    "        pcmfiles.extend(glob(os.path.join(dir, pattern)))\n",
    "    \n",
    "    for pcmfile in pcmfiles:\n",
    "        pcm_to_wav(pcmfile, os.path.join(rDots_home_dir, 'wav/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_prepare_files(rDots_home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_parse_ndx(ndx_dir, part_num):\n",
    "    genders = ['f', 'm']\n",
    "    file_names, spk_IDs, sent_IDs, trial_types = [], [], [], []\n",
    "    \n",
    "    for gender in genders:\n",
    "        with open(ndx_dir + gender + '_part_0' + str(part_num) + '.ndx', 'r') as ndx:\n",
    "            lines = ndx.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                [spk_sent, utterance, TC, TW, IC, IW] = line.split(',')\n",
    "                file_names.append(utterance)\n",
    "                \n",
    "                [spk, sent] = spk_sent.split('_')\n",
    "                spk_IDs.append(spk)\n",
    "                sent_IDs.append(int(sent))\n",
    "                \n",
    "                if TC=='Y': trial_types.append(0) \n",
    "                elif TW=='Y': trial_types.append(1) \n",
    "                elif IC=='Y': trial_types.append(2) \n",
    "                elif IW=='Y': trial_types.append(3) \n",
    "    return [file_names, spk_IDs, sent_IDs, trial_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_parse_trn(trn_dir, part_num):\n",
    "    genders = ['f', 'm']\n",
    "    spk_ID, sent_ID, file1_name, file2_name, file3_name = [], [], [], [], []\n",
    "    \n",
    "    for gender in genders:\n",
    "        with open(trn_dir + gender + '_part_0' + str(part_num) + '.trn', 'r') as trn:\n",
    "            lines = trn.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                [spk_sent, utters] = line.split(' ')\n",
    "                [utter1, utter2, utter3] = utters.split(',')\n",
    "                [spk, sent] = spk_sent.split('_')\n",
    "                spk_ID.append(spk)\n",
    "                sent_ID.append(int(sent))\n",
    "                file1_name.append(utter1)\n",
    "                file2_name.append(utter2)\n",
    "                file3_name.append(utter3)\n",
    "    return [spk_ID, sent_ID, file1_name, file2_name, file3_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_spkID_to_label(spk_IDs):\n",
    "    label = []\n",
    "    mapping = {}\n",
    "    count = 0\n",
    "    for spk_ID in spk_IDs:\n",
    "        if spk_ID not in mapping:\n",
    "            label.append(count)\n",
    "            mapping[spk_ID] = count\n",
    "            count += 1\n",
    "        else:\n",
    "            label.append(mapping[spk_ID])\n",
    "    '''\n",
    "    @return vars\n",
    "    label: list type, contains numerical labels for whole spk_IDs \n",
    "    mapping: dict type, contains mapping between actual speaker & numerical label\n",
    "    '''\n",
    "    return label, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_get_target_spk(infos_dir):\n",
    "    genders = ['f', 'm']\n",
    "    spk_IDs = []\n",
    "    \n",
    "    for gender in genders:\n",
    "        with open(infos_dir + gender + '_target.txt', 'r') as infos:\n",
    "            lines = infos.readlines()\n",
    "            for line in lines:\n",
    "                spk_IDs.append(line.split(';')[0])\n",
    "    return spk_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_get_imposter_spk(infos_dir):\n",
    "    genders = ['f', 'm']\n",
    "    spk_IDs = []\n",
    "    \n",
    "    for gender in genders:\n",
    "        with open(infos_dir + gender + '_imposter.txt', 'r') as infos:\n",
    "            lines = infos.readlines()\n",
    "            for line in lines:\n",
    "                spk_IDs.append(line.split(';')[0])\n",
    "    return spk_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_make_manifest(rDots_home_dir, default, part_num=None, hard_separate=False, testPOI=None, sent_filter=None):\n",
    "    '''\n",
    "    :param default: True -> make iden manifest with given ndx & trn file / False -> exclude anything in testPOI & sent_filter\n",
    "    :param hard_separate: in defaulte mode, exclude all utterances by speakers on target list if True, exclude only those on\n",
    "                            ndx & trn file if False\n",
    "    '''\n",
    "    rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "    file_dirs = set(glob(rDots_wav_dir + '*/*'))\n",
    "    print(len(file_dirs))\n",
    "    spk_dirs = glob(rDots_wav_dir + '*/')\n",
    "    spk_IDs = set([spk_dir.split('/')[-2] for spk_dir in spk_dirs])\n",
    "    \n",
    "    \n",
    "    if default==True:\n",
    "        if part_num > 4 or part_num < 1 or not isinstance(part_num, int):\n",
    "            raise BaseException(\"Invalid part number (only 1~4 possible)\")\n",
    "            \n",
    "        rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "        rDots_trn_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "        \n",
    "        ndx_list = rDots_parse_ndx(rDots_ndx_dir, part_num)\n",
    "        trn_list = rDots_parse_trn(rDots_trn_dir, part_num)\n",
    "                \n",
    "        veri_spk_IDs = set(trn_list[0])\n",
    "        \n",
    "        if hard_separate is False:\n",
    "            iden_spk_IDs = list(spk_IDs)\n",
    "            iden_label_mapping = rDots_spkID_to_label(iden_spk_IDs)[1]\n",
    "            veri_file_dirs = [(rDots_wav_dir + file_name + '.wav') for file_name in ndx_list[0]]\n",
    "            for i in range(2, 5):\n",
    "                veri_file_dirs = veri_file_dirs + [(rDots_wav_dir + file_name + '.wav') for file_name in trn_list[i]]\n",
    "            \n",
    "            for file_dir in veri_file_dirs:\n",
    "                if '.' not in file_dir:\n",
    "                    print(file_dir)\n",
    "            veri_file_dirs = set(veri_file_dirs)\n",
    "            iden_file_dirs = list(file_dirs - veri_file_dirs)\n",
    "            veri_file_dirs = list(veri_file_dirs)\n",
    "        else:\n",
    "            iden_spk_IDs = list(spk_IDs - veri_spk_IDs)\n",
    "            iden_label_mapping = rDots_spkID_to_label(iden_spk_IDs)[1]\n",
    "            \n",
    "            veri_file_dirs = []\n",
    "            for veri_spk_ID in veri_spk_IDs:\n",
    "                veri_file_dirs = veri_file_dirs + glob(rDots_wav_dir + veri_spk_ID + '/*')\n",
    "            veri_file_dirs = set(veri_file_dirs)\n",
    "            \n",
    "            iden_file_dirs = list(file_dirs - veri_file_dirs)\n",
    "            veri_file_dirs = list(veri_file_dirs)\n",
    "        \n",
    "        iden_file_dirs = shuffle(iden_file_dirs)\n",
    "        veri_file_dirs = shuffle(veri_file_dirs)\n",
    "        \n",
    "        total_len = len(iden_file_dirs)\n",
    "        train_lim = int(total_len * 0.64)\n",
    "        val_lim = int(total_len * 0.8)\n",
    "        iden_datasets = {'train': iden_file_dirs[:train_lim], \n",
    "                         'val': iden_file_dirs[train_lim:val_lim],\n",
    "                         'test': iden_file_dirs[val_lim:]}\n",
    "        \n",
    "        for dataset in iden_datasets.keys():\n",
    "            with open(\"../data/RedDots_iden_{}_manifest.csv\".format(dataset), \"w\") as f:\n",
    "                for file_dir in iden_datasets[dataset]:\n",
    "                    spk_ID = iden_label_mapping[file_dir.split('/')[-2]]\n",
    "                    f.write(file_dir + ',' + str(spk_ID))\n",
    "                    f.write('\\n')\n",
    "            f.close()\n",
    "                    \n",
    "        veri_train_c = list(itertools.combinations(iden_file_dirs[:int(total_len / 10)], 2))\n",
    "        veri_test_c = list(itertools.combinations(veri_file_dirs[:int(len(veri_file_dirs)/10)], 2))\n",
    "        veri_datasets = {'train': veri_train_c, 'test': veri_test_c}\n",
    "        \n",
    "        for dataset in veri_datasets.keys():\n",
    "            with open('../data/RedDots_veri_{}_manifest.csv'.format(dataset), \"w\") as f:\n",
    "                for data in veri_datasets[dataset]:\n",
    "                    line = data[0] + ',' + data[1] + ','\n",
    "                    if data[0].split('/')[-2] == data[1].split('/')[-2]:\n",
    "                        line = line + '1'\n",
    "                    else:\n",
    "                        line = line + '0'\n",
    "                    f.write(line)\n",
    "                    f.write('\\n')\n",
    "            f.close()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15305\n"
     ]
    }
   ],
   "source": [
    "rDots_make_manifest(rDots_home_dir, True, part_num=1, hard_separate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_RedDots_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "b = list(itertools.combinations(a, 2))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab\n",
    "data = np.memmap(rDots_pcm_dir + 'f0001/20150302171020760_f0001_58.pcm', dtype='h', mode='r')\n",
    "print (\"VALUES:\", data[:100])\n",
    "pylab.plot(data)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = glob(rDots_wav_dir + '*/')\n",
    "for subdir in subdirs:\n",
    "    print(subdir)\n",
    "    print(subdir.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

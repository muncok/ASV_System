{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %pylab inline\n",
    "import pandas\n",
    "import os\n",
    "os.sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VoxCeleb Dataset\n",
    "\n",
    "\n",
    "|                 | dev     | test  |\n",
    "|-----------------|---------|-------|\n",
    "| # of speakers   | 1,211   | 40    |\n",
    "| # of videos     | 21,819  | 677   |\n",
    "| # of utterances | 139,124 | 6,255 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "data_dir = \"/home/muncok/DL/dataset/voxceleb/\"\n",
    "wav_files = {}\n",
    "all_spks = []\n",
    "for _, dirnames, _ in os.walk(data_dir):\n",
    "    for dirname in dirnames:\n",
    "        if os.path.isfile(os.path.abspath(dirname)): continue\n",
    "        spk = dirname\n",
    "        all_spks.append(spk)\n",
    "        for filename in os.listdir(os.path.join(data_dir,dirname)):\n",
    "            uniqID = filename.split('.')[0]\n",
    "            wav_files[uniqID] = (spk, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame.from_dict(wav_files, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set df's column names\n",
    "df.columns = ['spk', 'file']\n",
    "df['set'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read set devision lists\n",
    "train_list = []\n",
    "test_list = []\n",
    "val_list = []\n",
    "        \n",
    "with open(\"/home/muncok/DL/dataset/voxceleb/Identification_split.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        set_id, filepath = line.split(' ')\n",
    "        uniqID = filepath.split('/')[-1].rstrip().rstrip(\".wav\")\n",
    "        if set_id == '1':\n",
    "            df.loc[uniqID].set = 'train'\n",
    "        elif set_id == '2':\n",
    "            df.loc[uniqID].set = 'val'\n",
    "        elif set_id == '3':\n",
    "            df.loc[uniqID].set = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of speakers: 1251\n"
     ]
    }
   ],
   "source": [
    "print(\"number of speakers: {}\".format(len(all_spks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rob_Reiner              1002\n",
       "Bob_Barker               656\n",
       "Alan_Alda                586\n",
       "Stephen_Fry              570\n",
       "Louis_C.K.               489\n",
       "Peter_Jackson            476\n",
       "Vince_Gilligan           468\n",
       "J.J._Abrams              426\n",
       "Quentin_Tarantino        409\n",
       "David_Attenborough       401\n",
       "Meat_Loaf                394\n",
       "Gloria_Steinem           381\n",
       "Tom_Hooper               377\n",
       "Lucie_Arnaz              374\n",
       "James_Woods              364\n",
       "Shonda_Rhimes            363\n",
       "Vidya_Balan              357\n",
       "Kal_Penn                 356\n",
       "Kriti_Sanon              347\n",
       "Dick_Van_Dyke            343\n",
       "Garry_Marshall           340\n",
       "Neil_deGrasse_Tyson      336\n",
       "Ricky_Gervais            335\n",
       "John_Noble               334\n",
       "Tom_Ford                 332\n",
       "Irrfan_Khan              330\n",
       "Kenny_Rogers             326\n",
       "Claudia_Black            317\n",
       "Brett_Davern             316\n",
       "Don_Rickles              314\n",
       "                        ... \n",
       "Damon_Wayans              47\n",
       "Michael_Weatherly         47\n",
       "Thomas_Jane               47\n",
       "Beth_Grant                47\n",
       "Blake_Michael             47\n",
       "Marisa_Miller             47\n",
       "Shemar_Moore              47\n",
       "Shiri_Appleby             47\n",
       "Julianne_Nicholson        46\n",
       "Donal_Logue               46\n",
       "Walter_Matthau            46\n",
       "Steve_Harvey              46\n",
       "Ellen_Burstyn             46\n",
       "Raoul_Bova                46\n",
       "Alex_Pettyfer             46\n",
       "Audrina_Patridge          46\n",
       "Will_Mellor               45\n",
       "Kim_Zolciak-Biermann      45\n",
       "Dane_Cook                 45\n",
       "Katie_Stevens             45\n",
       "Gary_Busey                45\n",
       "Max_Thieriot              45\n",
       "Leslie_Bibb               45\n",
       "Fanny_Ardant              45\n",
       "Jason_Dohring             45\n",
       "Chris_Lowell              45\n",
       "Shannen_Doherty           44\n",
       "Iain_Glen                 42\n",
       "Jennifer_Coolidge         42\n",
       "Steve_Burton              35\n",
       "Name: spk, Length: 1251, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utterances for each speaker\n",
    "df.spk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = [all_spks.index(x) for x in df.spk]\n",
    "df = df.assign(label = new_col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Voxc_Dataframes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict speakers\n",
    "chosen_spks = df.spk.value_counts().index[:100].tolist()\n",
    "\n",
    "sv_test = df[(df.set == 'test') & (df.spk.isin(chosen_spks))]\n",
    "sv_val = df[(df.set == 'val') & (df.spk.isin(chosen_spks))]\n",
    "sv_train = df[(df.set == 'train') & (df.spk.isin(chosen_spks))]\n",
    "\n",
    "import csv\n",
    "tags = ['train', 'val', 'test']\n",
    "sets = {'train':sv_train, 'val':sv_val, 'test':sv_test}\n",
    "for tag in tags:\n",
    "    samples = []\n",
    "    with open('sv_voxc_{}_manifest.csv'.format(tag), 'w') as f:\n",
    "        for index, row in sets[tag].iterrows():\n",
    "            file_path = os.path.join(data_dir, row.spk, row.file)\n",
    "            label = chosen_spks.index(row.spk)          \n",
    "            sample = ','.join([file_path, str(label+2)]) # 0,1 for speacial purpose\n",
    "            samples.append(sample)\n",
    "        random.shuffle(samples)\n",
    "        writer = csv.writer(f, delimiter='\\n', quoting=csv.QUOTE_NONE)\n",
    "        writer.writerow(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
